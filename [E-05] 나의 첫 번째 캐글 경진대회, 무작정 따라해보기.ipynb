{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "38bfbd5ada16035c96bb21265c51de80361f17b4"
   },
   "source": [
    "# 나의 첫 번째 캐글 경진대회, 무작정 따라해보기\n",
    "\n",
    "### 본 프로젝트는 2019 2nd ML month with KaKR : House Price Prediction에서 자료를 가져와  아이펠 조원들과 데이터 분석, 전처리, 모델링을 통해 집값 예측을 해봄.\n",
    "\n",
    "\n",
    "## 프로젝트 루브릭\n",
    "- 데이터 전처리, 모델학습, 예측의 전체 과정을 거쳐 캐글 submission까지 전과정이 성공적으로 진행되었는가?\n",
    "- 제출된 노트북이 캐글 커널로 사용될 수 있을 만큼 전처리, 학습, 최적화 진행 과정이 체계적으로 기술되었는가?\n",
    "- 다양한 피처 엔지니어링과 하이퍼 파라미터 튜닝 등의 최적화 기법을 통해 캐글 리더보드의 Private score 기준 110000 이하의 점수를 얻었는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 용어정리\n",
    "- max_depth : 의사 결정 나무의 깊이, 정수 사용\n",
    "- learning_rate : 한 스텝에 이동하는 양을 결정하는 파라미터, 보통 0.0001~0.1 사이의 실수 사용\n",
    "- n_estimators : 사용하는 개별 모델의 개수, 보통 50~100 이상의 정수 사용\n",
    "- num_leaves : 하나의 LightGBM 트리가 가질 수 있는 최대 잎의 수\n",
    "- boosting_type : 부스팅 방식, gbdt, rf 등의 문자열 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리 import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_profiling\n",
      "  Downloading pandas_profiling-3.1.0-py2.py3-none-any.whl (261 kB)\n",
      "     |████████████████████████████████| 261 kB 6.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (3.4.3)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (6.0)\n",
      "Collecting joblib~=1.0.1\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "     |████████████████████████████████| 303 kB 110.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (1.3.3)\n",
      "Collecting visions[type_image_path]==0.7.4\n",
      "  Downloading visions-0.7.4-py3-none-any.whl (102 kB)\n",
      "     |████████████████████████████████| 102 kB 21.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (1.7.1)\n",
      "Requirement already satisfied: missingno>=0.4.2 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (0.5.0)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (0.11.2)\n",
      "Collecting multimethod>=1.4\n",
      "  Downloading multimethod-1.7-py3-none-any.whl (9.5 kB)\n",
      "Collecting phik>=0.11.1\n",
      "  Downloading phik-0.12.0-cp39-cp39-manylinux2010_x86_64.whl (676 kB)\n",
      "     |████████████████████████████████| 676 kB 87.1 MB/s            \n",
      "\u001b[?25hCollecting htmlmin>=0.1.12\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tangled-up-in-unicode==0.1.0\n",
      "  Downloading tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1 MB)\n",
      "     |████████████████████████████████| 3.1 MB 61.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: jinja2>=2.11.1 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (3.0.3)\n",
      "Requirement already satisfied: requests>=2.24.0 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (1.21.4)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (4.62.3)\n",
      "Requirement already satisfied: markupsafe~=2.0.1 in /opt/conda/lib/python3.9/site-packages (from pandas_profiling) (2.0.1)\n",
      "Collecting pydantic>=1.8.1\n",
      "  Downloading pydantic-1.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "     |████████████████████████████████| 12.2 MB 24.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.9/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (2.6.3)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /opt/conda/lib/python3.9/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (21.2.0)\n",
      "Collecting imagehash\n",
      "  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n",
      "     |████████████████████████████████| 812 kB 45.8 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from visions[type_image_path]==0.7.4->pandas_profiling) (8.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.2.0->pandas_profiling) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.2.0->pandas_profiling) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.2.0->pandas_profiling) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.2.0->pandas_profiling) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas_profiling) (2021.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic>=1.8.1->pandas_profiling) (4.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.24.0->pandas_profiling) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.24.0->pandas_profiling) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.24.0->pandas_profiling) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.24.0->pandas_profiling) (2.0.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.0->pandas_profiling) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in /opt/conda/lib/python3.9/site-packages (from imagehash->visions[type_image_path]==0.7.4->pandas_profiling) (1.2.0)\n",
      "Building wheels for collected packages: htmlmin, imagehash\n",
      "  Building wheel for htmlmin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=a622aaacade26af4466208d038332ba10471420a041af1d4e013317205af5558\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/1d/05/04/c6d7d3b66539d9e659ac6dfe81e2d0fd4c1a8316cc5a403300\n",
      "  Building wheel for imagehash (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295207 sha256=56a7f6676084cb9b4cc1ecaac68ea27d9dd670259a63e30c65a56276778f338a\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/51/f9/a5/740af2fdb0ad1edf79aabdc41531be0b6f0b2e2be684c388cf\n",
      "Successfully built htmlmin imagehash\n",
      "Installing collected packages: tangled-up-in-unicode, multimethod, visions, joblib, imagehash, pydantic, phik, htmlmin, pandas-profiling\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed htmlmin-0.1.12 imagehash-4.2.1 joblib-1.0.1 multimethod-1.7 pandas-profiling-3.1.0 phik-0.12.0 pydantic-1.9.0 tangled-up-in-unicode-0.1.0 visions-0.7.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.0.4-cp39-none-manylinux1_x86_64.whl (76.2 MB)\n",
      "     |████████████████████████████████| 76.2 MB 143 kB/s            \n",
      "\u001b[?25hCollecting plotly\n",
      "  Downloading plotly-5.6.0-py2.py3-none-any.whl (27.7 MB)\n",
      "     |████████████████████████████████| 27.7 MB 61.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.21.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.3.3)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.19.1-py3-none-any.whl (46 kB)\n",
      "     |████████████████████████████████| 46 kB 7.1 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from catboost) (3.4.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from catboost) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (3.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (8.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly, graphviz, catboost\n",
      "Successfully installed catboost-1.0.4 graphviz-0.19.1 plotly-5.6.0 tenacity-8.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas_profiling\n",
    "! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'   # 그래프를 더 높은 해상도로 출력한다.\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import scipy as sp\n",
    "import folium \n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import statsmodels.api as sm\n",
    "# pip install catboost\n",
    "from sklearn.model_selection import KFold \n",
    "from scipy.stats import norm\n",
    "from scipy import stats, linalg\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from folium import plugins\n",
    "from sklearn import linear_model \n",
    "from sklearn import neighbors \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn import preprocessing \n",
    "from math import log\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "7d34243045b8e681bf168dc908a9388a2ceb5fa3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data dim : (15035, 21)\n",
      "test data dim : (6468, 20)\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data/'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "test_data_path = join(data_dir, 'test.csv')      # 테스트, 즉 submission 시 사용할 데이터 경로\n",
    "\n",
    "# 데이터를 df_train, df_test이라는 변수로 불러오기\n",
    "df_train = pd.read_csv(train_data_path)\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "print('train data dim : {}'.format(df_train.shape))\n",
    "print('test data dim : {}'.format(df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train 데이터는 약 1만 5천 개, Test 데이터는 약 6천 개로 이루어져 있음\n",
    "- Train 데이터와 Test 데이터의 비율은 5:2로 심하게 불균등하지 않음.\n",
    "- 테스트 데이터는 물론 우리가 맞추어야 할 집의 가격, price가 없기 때문에 컬럼이 하나 적음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f0d3320a32138c92ed7b0629a57bd5a719603b0"
   },
   "source": [
    "##  데이터 분석 (변수 확인)\n",
    "\n",
    "pandas의 read_csv 함수를 사용해 데이터를 읽어옴\n",
    "1. ID : 집을 구분하는 번호\n",
    "2. date : 집을 구매한 날짜\n",
    "3. price : 타겟 변수인 집의 가격\n",
    "4. bedrooms : 침실의 수\n",
    "5. bathrooms : 침실당 화장실 개수\n",
    "6. sqft_living : 주거 공간의 평방 피트\n",
    "7. sqft_lot : 부지의 평방 피트\n",
    "8. floors : 집의 층 수\n",
    "9. waterfront : 집의 전방에 강이 흐르는지 유무 (a.k.a. 리버뷰)\n",
    "10. view : 집이 얼마나 좋아 보이는지의 정도\n",
    "11. condition : 집의 전반적인 상태\n",
    "12. grade : King County grading 시스템 기준으로 매긴 집의 등급\n",
    "13. sqft_above : 지하실을 제외한 평방 피트\n",
    "14. sqft_basement : 지하실의 평방 피트\n",
    "15. yr_built : 집을 지은 년도\n",
    "16. yr_renovated : 집을 재건축한 년도\n",
    "17. zipcode : 우편번호\n",
    "18. lat : 위도\n",
    "19. long : 경도\n",
    "20. sqft_living15 : 2015년 기준 주거 공간의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)\n",
    "21. sqft_lot15 : 2015년 기준 부지의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>291850.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0   0  20141013T000000  221900.0         3       1.00         1180      5650   \n",
       "1   1  20150225T000000  180000.0         2       1.00          770     10000   \n",
       "2   2  20150218T000000  510000.0         3       2.00         1680      8080   \n",
       "3   3  20140627T000000  257500.0         3       2.25         1715      6819   \n",
       "4   4  20150115T000000  291850.0         3       1.50         1060      9711   \n",
       "\n",
       "   floors  waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "0     1.0           0     0          3      7        1180              0   \n",
       "1     1.0           0     0          3      6         770              0   \n",
       "2     1.0           0     0          3      8        1680              0   \n",
       "3     2.0           0     0          3      7        1715              0   \n",
       "4     1.0           0     0          3      7        1060              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1933             0    98028  47.7379 -122.233           2720   \n",
       "2      1987             0    98074  47.6168 -122.045           1800   \n",
       "3      1995             0    98003  47.3097 -122.327           2238   \n",
       "4      1963             0    98198  47.4095 -122.315           1650   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        8062  \n",
       "2        7503  \n",
       "3        6819  \n",
       "4        9711  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- date : yyyymmdd + T000000의 형태. 필요한 부분은 앞의 8자리(yyyymmdd)\n",
    "- bathroom : 소수점 형태\n",
    "- yr_renovated : 0인 값은 재건축을 하지 않았다는 의미\n",
    "- 앞으로 하나하나 변수를 살펴보면서 전처리와 피쳐 엔지니어링에 대해 고민해봄."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94ad23d7a91a68c1be7fcd4953013f5353541545"
   },
   "source": [
    "### id, date 변수 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15035 entries, 0 to 15034\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             15035 non-null  int64  \n",
      " 1   date           15035 non-null  object \n",
      " 2   price          15035 non-null  float64\n",
      " 3   bedrooms       15035 non-null  int64  \n",
      " 4   bathrooms      15035 non-null  float64\n",
      " 5   sqft_living    15035 non-null  int64  \n",
      " 6   sqft_lot       15035 non-null  int64  \n",
      " 7   floors         15035 non-null  float64\n",
      " 8   waterfront     15035 non-null  int64  \n",
      " 9   view           15035 non-null  int64  \n",
      " 10  condition      15035 non-null  int64  \n",
      " 11  grade          15035 non-null  int64  \n",
      " 12  sqft_above     15035 non-null  int64  \n",
      " 13  sqft_basement  15035 non-null  int64  \n",
      " 14  yr_built       15035 non-null  int64  \n",
      " 15  yr_renovated   15035 non-null  int64  \n",
      " 16  zipcode        15035 non-null  int64  \n",
      " 17  lat            15035 non-null  float64\n",
      " 18  long           15035 non-null  float64\n",
      " 19  sqft_living15  15035 non-null  int64  \n",
      " 20  sqft_lot15     15035 non-null  int64  \n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 타입이 대부분 실수, 정수로 이루어져 있으나, date는 objcet로 되어있다.\n",
    "앞에서 확인한 바와 같이 date는 yyyymmdd + T000000의 형태로 되어있음.\n",
    "필요한 부분인 앞의 8자리(yyyymmdd)만 불러와 정수형태로 바꿔야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'data_ID' 변수에 `id`칼럼 저장\n",
    "df_train_ID = df_train['id']\n",
    "df_test_ID = df_test['id']\n",
    "\n",
    "# `id` 칼럼 삭제\n",
    "df_train.drop(\"id\", axis = 1, inplace = True)\n",
    "df_test.drop(\"id\", axis = 1, inplace = True)\n",
    "\n",
    "# date 컬럼은 apply 함수로 필요한 부분만 잘라준다.\n",
    "df_train['date'] = df_train['date'].apply(lambda x : str(x[:6]))\n",
    "df_test['date'] = df_test['date'].apply(lambda x : str(x[:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201410</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201502</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201502</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201406</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201501</td>\n",
       "      <td>291850.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "0  201410  221900.0         3       1.00         1180      5650     1.0   \n",
       "1  201502  180000.0         2       1.00          770     10000     1.0   \n",
       "2  201502  510000.0         3       2.00         1680      8080     1.0   \n",
       "3  201406  257500.0         3       2.25         1715      6819     2.0   \n",
       "4  201501  291850.0         3       1.50         1060      9711     1.0   \n",
       "\n",
       "   waterfront  view  condition  grade  sqft_above  sqft_basement  yr_built  \\\n",
       "0           0     0          3      7        1180              0      1955   \n",
       "1           0     0          3      6         770              0      1933   \n",
       "2           0     0          3      8        1680              0      1987   \n",
       "3           0     0          3      7        1715              0      1995   \n",
       "4           0     0          3      7        1060              0      1963   \n",
       "\n",
       "   yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0             0    98178  47.5112 -122.257           1340        5650  \n",
       "1             0    98028  47.7379 -122.233           2720        8062  \n",
       "2             0    98074  47.6168 -122.045           1800        7503  \n",
       "3             0    98003  47.3097 -122.327           2238        6819  \n",
       "4             0    98198  47.4095 -122.315           1650        9711  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요 없는 id 컬럼 제거\n",
    "- 나중에 예측 결과를 제출할 때를 대비해 'train_ID' 변수에 id칼럼 저장\n",
    "- date를 필요한 부분인 앞의 8자리(yyyymmdd)만 표현해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(df_train)\n",
    "msno.matrix(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 종속변수 시각화 (price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.503500e+04\n",
       "mean     5.406827e+05\n",
       "std      3.715247e+05\n",
       "min      7.800000e+04\n",
       "25%      3.220000e+05\n",
       "50%      4.500000e+05\n",
       "75%      6.450000e+05\n",
       "max      7.700000e+06\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "price의 경우 min, max의 차이가 크고, std가 굉장히 크다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='price', ylabel='Density'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# price의 histogram\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.distplot(df_train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness(왜도): 4.290252\n",
      "Kurtosis(첨도): 40.154919\n"
     ]
    }
   ],
   "source": [
    "# 왜도, 첨도 확인하기\n",
    "print(\"Skewness(왜도): %f\" % df_train['price'].skew())\n",
    "print(\"Kurtosis(첨도): %f\" % df_train['price'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 수치 상으로나, 그래프 상으로나 price의 수치들이 굉장히 편향되어있다는 것을 확인할 수 있음..\n",
    "- 예측모델을 회귀모델을 사용할 예정이므로 Normalize를 통해 정규분포를 가지도록 만들어줌.\n",
    "\n",
    "- 왜도와 첨도 이해하기\n",
    "  - 왜도 : symmetrical bell curve 혹은 normal distribution에서 왜곡 정도를 말함. 데이터 분포의 대칭성이 얼마나 결핍되었는지를 측정함. 완전히 대칭인 분포는 skewness가 0임.\n",
    "  - 첨도 : 첨도는 분포 그래프의 꼬리 부분에 관한 것. 정점(peakness)이나 평탄도(flatness)가 아님. 극단적인 값들을 한 꼬리와 다른 꼬리로 설명하는 데 사용됨. 분포에 존재하는 특이치(outlier)의 척도임\n",
    "  \n",
    "표준 정규 분포는 3의 첨도 갖게됨.\n",
    "\n",
    "Leptokurtic (Kurtosis > 3) : 분포가 길고, 꼬리가 더 뚱뚱함. 피크는 Mesokurtic보다 높고 날카롭기 때문에 데이터는 꼬리가 무겁거나 특이치(outlier)가 많다는 것을 의미함.\n",
    "\n",
    "Platykurtic (Kurtosis < 3) : 분포는 짧고 꼬리는 정규 분포보다 얇음. 피크는 Mesokurtic보다 낮고 넓으며, 이는 데이터가 가벼운 편이나 특이치(outlier)가 부족하다는 것을 의미함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,5))\n",
    "# Normalize 전\n",
    "fig.add_subplot(1,2,1)\n",
    "res = stats.probplot(df_train['price'], plot=plt)\n",
    "# Normalize 후\n",
    "fig.add_subplot(1,2,2)\n",
    "res = stats.probplot(np.log1p(df_train['price']), plot=plt)   # 로그변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='price', ylabel='Density'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['price'] = np.log1p(df_train['price'])   # 로그변환\n",
    "#price의 normalize 후 histogram\n",
    "f, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.distplot(df_train['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위와 같이 price에 log를 취하면 정규성을 띄게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석\n",
    "\n",
    "독립변수 시각화 (다양한 변수) - 종속변수와의 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 세트에서 사용할 수 있는 독립변수와 예측하려는 종속변수(가격) 간의 관계를 분석함.\n",
    "- 변수 간의 잠재적 연관성을 탐색하기 위해 산점도와 상관계수(Pearson, Spearman)를 사용함.\n",
    "- 연속형 변수(Continuous Variables), 범주형 변수(Categorical Variables)로 나눠서 확인함.\n",
    "\n",
    "- 참고 : https://lunch-box.tistory.com/94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 연속형 변수(Continuous Variables)\n",
    "\n",
    "- sqft_living\n",
    "- sqft_lot\n",
    "- sqft_above (i.e., sqft_above = sqft_living - sqft_basement)\n",
    "- sqft_basement\n",
    "- sqft_living15, the average house square footage of the 15 closest neighbours\n",
    "- sqft_lot15, the average lot square footage of the 15 closest neighbours\n",
    "- yr_built\n",
    "- yr_renovated\n",
    "- lat\n",
    "- long\n",
    "\n",
    "(1) sqft_living과 price 간의 관계를 분석해봄.\n",
    "\n",
    "\n",
    "(2) 두 변수는 연속형 변수이므로 Pearson계수 을 사용해 관계의 강도와 방향을 측정할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6979070299928941, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(x=df_train[\"sqft_living\"], y=df_train[\"price\"]))\n",
    "sns.jointplot(x=\"sqft_living\", y=\"price\", data=df_train, kind = 'reg', size = 7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 변수 사이에는 명확한 선형 연관성이 있으며(), 강한 양의 관계를 나타냄.\n",
    "- sqft_living은 집값의 좋은 예측 변수로 사용할 수 있음.\n",
    "- sqft_living 분포도 왼쪽으로 치우쳐 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6071968710886724, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(x=df_train[\"sqft_above\"], y=df_train[\"price\"]))\n",
    "sns.jointplot(x=\"sqft_above\", y=\"price\", data=df_train, kind = 'reg', size = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3143778619617312, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(x=df_train[\"sqft_basement\"], y=df_train[\"price\"]))\n",
    "sns.jointplot(x=\"sqft_basement\", y=\"price\", data=df_train, kind = 'reg', size = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6218002043419212, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(x=df_train[\"sqft_living15\"], y=df_train[\"price\"]))\n",
    "sns.jointplot(x=\"sqft_living15\", y=\"price\", data=df_train, kind = 'reg', size = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0969762247337608, 9.528900012032072e-33)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(x=df_train[\"sqft_lot15\"], y=df_train[\"price\"]))\n",
    "sns.jointplot(x=\"sqft_lot15\", y=\"price\", data=df_train, kind = 'reg', size = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0762934274348525, 7.40806968627676e-21)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(x=df_train[\"yr_built\"], y=df_train[\"price\"]))\n",
    "sns.jointplot(x=\"yr_built\", y=\"price\", data=df_train, kind = 'reg', size = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1275327318738892, 1.4990191405098697e-55)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(x=df_train[\"yr_renovated\"], y=df_train[\"price\"]))\n",
    "sns.jointplot(x=\"yr_renovated\", y=\"price\", data=df_train, kind = 'reg', size = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.44441709755426134, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(x=df_train[\"lat\"], y=df_train[\"price\"]))\n",
    "sns.jointplot(x=\"lat\", y=\"price\",data=df_train, kind = 'reg', size = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.05436231117602357, 2.555640631768941e-11)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pearsonr(x=df_train[\"long\"], y=df_train[\"price\"]))\n",
    "sns.jointplot(x=\"long\", y=\"price\", data=df_train, kind = 'reg', size = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sqft_lot, sqft_lot15 및 yr_built는 가격과 관련이 없는 것 같음.\n",
    "- sqft_basement 분포에 0이 많이 있음을 알 수 있음.이는 지하실이 없는 주택을 나타냄. (이 경우 sqft_lving = sqft_above)\n",
    "- 마찬가지로, yr_renovated 변수에는 0이 많이 있어 특정 항목이 개조된 적이 없음을 나타냄.\n",
    "- 0이 없는 이 두 변수에 대한 연관 테스트를 다시 실행해봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석을 위한 2개의 새로운 칼럼을 만든다.\n",
    "df_train['sqft_basement2'] = df_train['sqft_basement'].apply(lambda x: x if x > 0 else None)\n",
    "df_train['yr_renovated2'] = df_train['yr_renovated'].apply(lambda x: x if x > 0 else None)\n",
    "\n",
    "# 다시 그래프 그리기\n",
    "sns.jointplot(x=\"sqft_basement2\", y=\"price\", data=df_train, kind = 'reg', dropna=True, size = 6)\n",
    "sns.jointplot(x=\"yr_renovated2\", y=\"price\", data=df_train, kind = 'reg', dropna=True, size = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- price는 지하실의 크기와 중간 정도의 상관관계가 있음. (지하실이 있는 경우)\n",
    "- 재건축 연도(재건축된 경우)와도 약간의 상관관계가 있음.\n",
    "- 여기에서는 지하실과 재건축 값을 이분법적 변수로 분류해 사용함.(지하실이 없는 경우 0, 지하실이 있는 경우 1)\n",
    "- 데이터 세트에 각각 새 열을 생성함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['basement_present'] = df_train['sqft_basement'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_train['basement_present'] = df_train['basement_present'].astype('category')\n",
    "\n",
    "df_train['renovated'] = df_train['yr_renovated'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_train['renovated'] = df_train['renovated'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 새로 만들어진 변수를 범주형으로 분석함\n",
    "- 그 전에 sqft_above 및 sqft_living15를 살펴봄.\n",
    "- seaborn의 pairgrid() 함수를 사용하여 이들의 연관성(sqft_living과 함께)을 분석함.\n",
    "- 대각선 축에 각 변수의 분포를 그리고 위쪽 대각선에 산점도를 사용하고, 아래쪽 대각 선에 커널 밀도 추정을 사용하여 분포를 그린다. 각 쌍의 페어슨 계수를 표시하는 함수를 생성함.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"pearsonr = {:.2f}\".format(r),\n",
    "                xy=(.1, .9), xycoords=ax.transAxes)\n",
    "\n",
    "g = sns.PairGrid(df_train, vars = ['sqft_living', 'sqft_living15', 'sqft_above'], size = 3.5)\n",
    "g.map_upper(plt.scatter) \n",
    "g.map_diag(sns.distplot)\n",
    "g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "g.map_lower(corrfunc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예상대로 3개의 변수 사이에는 강한 양의 관계가 확인됨\n",
    "- sqft_livng - sqft_basement = sqft_above의 관계를 갖기 때문에 둘 다 price에 영향을 미친다는 것은 예상 가능한 부분임\n",
    "- 그러나 sqft_living15의 경우 price와의 관계가 15가구의 평방 피트 때문인지는 확실하지 않음. 이는 sqft_living15와 sqft_living 사이의 높은 상관 관계 때문와 sqft_living 사이의 높은 상관 관계 때문임.\n",
    "- price와 sqft_living15 사이의 관계를 명확하게 평가하기 위해 Pearson Partial Correlation test를 사용함.\n",
    "- 상관 관계는 공변량(covariate)이라고 하는 다른 연속 변수의 효과를 제어하면서 두 연속 변수 간의 연관성을 평가할 수 있음.\n",
    "- 여기서는 sqft_living을 공변량으로 사용하여 price와 sqft_living15 간의 관계를 확인함.\n",
    "\n",
    "\n",
    "- 공변량 : 독립변수라기 보다는 하나의 개념으로서 여러 변수들이 공통적으로 함께 공유하고 있는 변량\n",
    "- 참고 : https://m.blog.naver.com/imchaehong/10033930690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.08098428, 0.56430788],\n",
       "       [0.08098428, 1.        , 0.72311321],\n",
       "       [0.56430788, 0.72311321, 1.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partial_corr(C):\n",
    "    C = np.asarray(C)\n",
    "    p = C.shape[1]\n",
    "    P_corr = np.zeros((p, p), dtype=np.float)\n",
    "    for i in range(p):\n",
    "        P_corr[i, i] = 1\n",
    "        for j in range(i+1, p):\n",
    "            idx = np.ones(p, dtype=np.bool)\n",
    "            idx[i] = False\n",
    "            idx[j] = False\n",
    "            beta_i = linalg.lstsq(C[:, idx], C[:, j])[0]\n",
    "            beta_j = linalg.lstsq(C[:, idx], C[:, i])[0]\n",
    "            res_j = C[:, j] - C[:, idx].dot(beta_i)\n",
    "            res_i = C[:, i] - C[:, idx].dot(beta_j)            \n",
    "            corr = stats.pearsonr(res_i, res_j)[0]\n",
    "            P_corr[i, j] = corr\n",
    "            P_corr[j, i] = corr\n",
    "    return P_corr\n",
    "\n",
    "partial_corr_array_df = pd.DataFrame(df_train, columns=['price', 'sqft_living', 'sqft_living15'])\n",
    "\n",
    "partial_corr_array = partial_corr_array_df.to_numpy()\n",
    "\n",
    "partial_corr(partial_corr_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주변 주택의 평균 주택 크기는 주택 크기를 제어할 때 판매 가격에 영향을 미치지 않음을 알 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 범주형 변수(Categorical Variables)\n",
    "- waterfront\n",
    "\n",
    "- basement_present\n",
    "- bathrooms\n",
    "- floors\n",
    "- view\n",
    "- condition\n",
    "- grade\n",
    "- price와 범주형 변수 간의 관계를 분석함\n",
    "- 첫 번째로, 리버뷰가 더 높은 집 가치와 관련이 있는지 평가해봄. waterfront는 기본 연속 분포가 있는 이분법 변수임.(waterfront가 있는 것이 waterfront가 없는 것보다 낫다).\n",
    "- point biserial correlation coefficient를 사용해 두 변수 간의 관계를 강조할 수 있음.\n",
    "- point biserial correlation coefficient : 한 변수는 있음/없음, 네/아니오 등으로 이분형(binary) 이고, 다른 한 변수는 연속형인 경우에도 상관계수를 나타낼 수 있음.\n",
    "- 참고 : https://mansoostat.tistory.com/115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point biserial correlation r is 0.1725802357222813 with p = 7.451854937555299e-101\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,4))\n",
    "sns.boxplot(y = 'waterfront', x = 'price', data = df_train, width = 0.8,orient = 'h', showmeans = True, fliersize = 3, ax = ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "r, p = stats.pointbiserialr(df_train['waterfront'], df_train['price'])\n",
    "print('point biserial correlation r is %s with p = %s' %(r,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 리버뷰가 없는 상자 플롯은 상대적으로 짧음\n",
    "- 이는 전반적으로 이 그룹의 price가 서로 비슷하다는 것을 의미함.\n",
    "- 리버뷰 상자 플롯은 비교적 김.\n",
    "- 이는 price가 이 그룹 안에서 서로 크게 다르다는 것을 의미함.\n",
    "- 두 분포 사이에는 분명한 형태 차이를 보이고 있으며, 일반적으로 리버뷰의 주택이 더 높은 price는 갖게됨.\n",
    "- 두 변수 사이의 상관관계가 작더라도 여기서 아래 3가지를 확인하지 않았기 때문에 결과에 너무 의존할 수는 없음.\n",
    "- 연속 변수의 관점에서 이분형 변수의 두 그룹에 중요한 이상값이 없어야 함.\n",
    "- 분산의 동질성이 있어야 함.\n",
    "- 연속 변수가 이분형 변수의 각 그룹에 대해 대략적으로 정규 분포를 가져야 함.\n",
    "- basement_present와 과거 재건축 여부에 대해서도 동일하게 진행함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point biserial correlation r between price and basement_present is 0.2077259024713432 with p = 3.221005298505754e-146\n",
      "point biserial correlation r between price and renovated is 0.127241496478846 with p = 2.6485103319969934e-55\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,4))\n",
    "sns.boxplot(y = 'basement_present', x = 'price', data =df_train, width = 0.8,orient = 'h', showmeans = True, fliersize = 3, ax = ax)\n",
    "plt.show()\n",
    "r, p = stats.pointbiserialr(df_train['basement_present'], df_train['price'])\n",
    "print('point biserial correlation r between price and basement_present is %s with p = %s' %(r,p))\n",
    "\n",
    "# renovated variable\n",
    "fig, ax = plt.subplots(figsize=(18,4))\n",
    "sns.boxplot(y = 'renovated', x = 'price', data = df_train, width = 0.8,orient = 'h', showmeans = True, fliersize = 3, ax = ax)\n",
    "plt.show()\n",
    "r, p = stats.pointbiserialr(df_train['renovated'], df_train['price'])\n",
    "print('point biserial correlation r between price and renovated is %s with p = %s' %(r,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 연관성이 거의 없다.(0.1 < r < 0.3)\n",
    "- 순위변수(ordinal variable)로 price와의 연관성을 확인해봄.\n",
    "- 박스플롯을 사용해 각 변수의 범주 분포를 보여줌.\n",
    "- 참고 : http://triki.net/study/3108#dry_toc_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(6, figsize=(18,40))\n",
    "sns.boxplot(y = 'bedrooms', x = 'price', data = df_train, width = 0.8,orient = 'h', showmeans = True, fliersize = 3, ax = axarr[0])\n",
    "sns.boxplot(y = 'bathrooms', x = 'price', data = df_train, width = 0.8,orient = 'h', showmeans = True, fliersize = 3, ax = axarr[1])\n",
    "sns.boxplot(y = 'floors', x = 'price', data = df_train, width = 0.8,orient = 'h', showmeans = True, fliersize = 3, ax = axarr[2])\n",
    "sns.boxplot(y = 'view', x = 'price', data = df_train, width = 0.8,orient = 'h', showmeans = True, fliersize = 3, ax = axarr[3])\n",
    "sns.boxplot(y = 'condition', x = 'price', data = df_train, width = 0.8,orient = 'h', showmeans = True, fliersize = 3, ax = axarr[4])\n",
    "sns.boxplot(y = 'grade', x = 'price', data = df_train, width = 0.8,orient = 'h', showmeans = True, fliersize = 3, ax = axarr[5])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예상한대로 모두 price와 관련이 있어 보임.\n",
    "- Spearman의 순위 상관 관계를 사용하여 price와 이러한 변수 간의 관계의 강도와 방향을 측정할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman correlation r between price and bedrooms is 0.3501849162071746 with p = 0.0\n",
      "spearman correlation r between price and bathrooms is 0.49898891562255676 with p = 0.0\n",
      "spearman correlation r between price and floors is 0.3286741155680268 with p = 0.0\n",
      "spearman correlation r between price and view is 0.29171951557401904 with p = 1.028069352380221e-292\n",
      "spearman correlation r between price and condition is 0.021520487889595537 with p = 0.008318284658970533\n",
      "spearman correlation r between price and grade is 0.6621252562728034 with p = 0.0\n"
     ]
    }
   ],
   "source": [
    "r, p = stats.spearmanr(df_train['bedrooms'], df_train['price'])\n",
    "print('spearman correlation r between price and bedrooms is %s with p = %s' %(r,p))\n",
    "r, p = stats.spearmanr(df_train['bathrooms'], df_train['price'])\n",
    "print('spearman correlation r between price and bathrooms is %s with p = %s' %(r,p))\n",
    "r, p = stats.spearmanr(df_train['floors'], df_train['price'])\n",
    "print('spearman correlation r between price and floors is %s with p = %s' %(r,p))\n",
    "r, p = stats.spearmanr(df_train['view'], df_train['price'])\n",
    "print('spearman correlation r between price and view is %s with p = %s' %(r,p))\n",
    "r, p = stats.spearmanr(df_train['condition'], df_train['price'])\n",
    "print('spearman correlation r between price and condition is %s with p = %s' %(r,p))\n",
    "r, p = stats.spearmanr(df_train['grade'], df_train['price'])\n",
    "print('spearman correlation r between price and grade is %s with p = %s' %(r,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수들과 price 사이에는 실제로 연관성이 있음. (condition 제외).\n",
    "grade가 가장 좋은 지표인 것 같음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석 결론\n",
    "\n",
    "- sqft_living, sqft_above 및 sqft_basement는 price와 적당히/강하게 연관이 있다. 3개의 변수는 sqft_living = sqft_above 및 sqft_basement와 같이 서로 밀접한 관련이 있다.\n",
    "- sqft_living15, 가장 가까운 이웃 15개 주택의 평균 면적도 price(r=)와 밀접한 관련이 있었다. 그러나 sqft_living을 제어할 때 관계가 사라졌다.\n",
    "- sqft_lot, sqft_lot15(가장 가까운 주택 15채의 평균 부지 크기) 및 yr_built는 가격과 관련성이 낮다.\n",
    "- 세 가지 변수(waterfront, basement_present, renovated)는 가격과 연관이 있었지만, 정도가 적게 나타났다.\n",
    "- 다음 5개 변수(bedrooms, bathrooms, floors, views, grade)도 가격과 중간 ~ 매우 강한 정도로 연관이 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 지정하기\n",
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "test_data_path = join(data_dir, 'test.csv')      # 테스트, 즉 submission 시 사용할 데이터 경로\n",
    "\n",
    "# 데이터를 df_train, df_test이라는 변수로 불러오기\n",
    "df_train = pd.read_csv(train_data_path)\n",
    "df_test = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price는 이전과 동일하게 정규화시켜줌.\n",
    "\n",
    "df_train['price'] = np.log1p(df_train['price'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분석으로 확인된 이상치 제거\n",
    "\n",
    "- 변수들에 대해 시각화하여 나타냈을 때, 다음 변수들에서 이상치가 확인되었음.\n",
    "- sqft_living\n",
    "- grade\n",
    "- bedrooms\n",
    "\n",
    "##### (1) sqft_living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_train['price'], df_train['sqft_living']], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.regplot(x='sqft_living', y=\"price\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>8912</td>\n",
       "      <td>20140505T000000</td>\n",
       "      <td>14.639686</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13540</td>\n",
       "      <td>307752</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>9410</td>\n",
       "      <td>4130</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6675</td>\n",
       "      <td>-121.986</td>\n",
       "      <td>4850</td>\n",
       "      <td>217800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "8912  8912  20140505T000000  14.639686         7        8.0        13540   \n",
       "\n",
       "      sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "8912    307752     3.0           0     4          3     12        9410   \n",
       "\n",
       "      sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "8912           4130      1999             0    98053  47.6675 -121.986   \n",
       "\n",
       "      sqft_living15  sqft_lot15  \n",
       "8912           4850      217800  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['sqft_living'] > 13000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 값을 봤을 때, 다른 값들에 비해 sqft_living만 비정상적으로 꽤 큰 것을 알 수 있음\n",
    "- 추가적으로 price와 상관성이 높은 grade와 다른 평수들을 살펴봐도 큰 의미는 없어보이므로 제거하도록 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train['id']!=8990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### (2) grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_train['price'], df_train['grade']], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x='grade', y=\"price\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>2302</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>12.476104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>520</td>\n",
       "      <td>12981</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>98022</td>\n",
       "      <td>47.2082</td>\n",
       "      <td>-121.995</td>\n",
       "      <td>1340</td>\n",
       "      <td>12233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>4123</td>\n",
       "      <td>20141104T000000</td>\n",
       "      <td>12.542548</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>600</td>\n",
       "      <td>24501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>1950</td>\n",
       "      <td>0</td>\n",
       "      <td>98045</td>\n",
       "      <td>47.5316</td>\n",
       "      <td>-121.749</td>\n",
       "      <td>990</td>\n",
       "      <td>22549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "2302  2302  20150225T000000  12.476104         1       0.75          520   \n",
       "4123  4123  20141104T000000  12.542548         1       0.00          600   \n",
       "\n",
       "      sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "2302     12981     1.0           0     0          5      3         520   \n",
       "4123     24501     1.0           0     0          2      3         600   \n",
       "\n",
       "      sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "2302              0      1920             0    98022  47.2082 -121.995   \n",
       "4123              0      1950             0    98045  47.5316 -121.749   \n",
       "\n",
       "      sqft_living15  sqft_lot15  \n",
       "2302           1340       12233  \n",
       "4123            990       22549  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[(df_train['price']>12) & (df_train['grade'] == 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- grade, sqft_ 모두 낮은 것을 볼 수 있음. \n",
    "- 이에  두 값 모두 이상치로 규정하고 제거하도록 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>7173</td>\n",
       "      <td>20140813T000000</td>\n",
       "      <td>14.808763</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4230</td>\n",
       "      <td>27295</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3230</td>\n",
       "      <td>1000</td>\n",
       "      <td>1949</td>\n",
       "      <td>1985</td>\n",
       "      <td>98033</td>\n",
       "      <td>47.6803</td>\n",
       "      <td>-122.214</td>\n",
       "      <td>2660</td>\n",
       "      <td>27295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "7173  7173  20140813T000000  14.808763         5        4.0         4230   \n",
       "\n",
       "      sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "7173     27295     2.0           1     4          3      8        3230   \n",
       "\n",
       "      sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "7173           1000      1949          1985    98033  47.6803 -122.214   \n",
       "\n",
       "      sqft_living15  sqft_lot15  \n",
       "7173           2660       27295  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[(df_train['price']>14.7) & (df_train['grade'] == 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>2775</td>\n",
       "      <td>20140611T000000</td>\n",
       "      <td>15.77031</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>10040</td>\n",
       "      <td>37325</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>7680</td>\n",
       "      <td>2360</td>\n",
       "      <td>1940</td>\n",
       "      <td>2001</td>\n",
       "      <td>98004</td>\n",
       "      <td>47.65</td>\n",
       "      <td>-122.214</td>\n",
       "      <td>3930</td>\n",
       "      <td>25449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "2775  2775  20140611T000000  15.77031         5        4.5        10040   \n",
       "\n",
       "      sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
       "2775     37325     2.0           1     2          3     11        7680   \n",
       "\n",
       "      sqft_basement  yr_built  yr_renovated  zipcode    lat     long  \\\n",
       "2775           2360      1940          2001    98004  47.65 -122.214   \n",
       "\n",
       "      sqft_living15  sqft_lot15  \n",
       "2775           3930       25449  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[(df_train['price']>15.5) & (df_train['grade'] == 11)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 값 모두 특별한 이유가 없이 가격이 높아 보이므로 이상치로 규정하고 제거하도록 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[df_train['id']!=2302]\n",
    "df_train = df_train.loc[df_train['id']!=4123]\n",
    "df_train = df_train.loc[df_train['id']!=7259]\n",
    "df_train = df_train.loc[df_train['id']!=2777]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_train['price'], df_train['bedrooms']], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x='bedrooms', y=\"price\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bedrooms를 보면 양의 상관관계를 띄고 있음.\n",
    "- 그리고 bedrooms가 2 ~ 6은 분산이 매우 큰 것을 확인할 수 있음.\n",
    "- 가운데의 값들은 다른 변수들의 영향이 크므로 제거하지는 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_columns = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']\n",
    "\n",
    "for c in skew_columns:\n",
    "    df_train[c] = np.log1p(df_train[c].values)\n",
    "    df_test[c] = np.log1p(df_test[c].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 변수 수정\n",
    "\n",
    "(1) date, sqft_basement, yr_renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    df['date'] = df['date'].apply(lambda x: x[0:8]).astype(int)\n",
    "    df['basement_present'] = df['sqft_basement'].apply(lambda x: 1 if x > 0 else 0)    # 지하실 유무\n",
    "    df['renovated'] = df['yr_renovated'].apply(lambda x: 1 if x > 0 else 0)           # 1이면 재건축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>basement_present</th>\n",
       "      <th>renovated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20141013</td>\n",
       "      <td>12.309987</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.074117</td>\n",
       "      <td>8.639588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7.074117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20150225</td>\n",
       "      <td>12.100718</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.647688</td>\n",
       "      <td>9.210440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6.647688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20150218</td>\n",
       "      <td>13.142168</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.427144</td>\n",
       "      <td>8.997271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7.427144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20140627</td>\n",
       "      <td>12.458779</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>7.447751</td>\n",
       "      <td>8.827615</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7.447751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20150115</td>\n",
       "      <td>12.583999</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>9.181118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      date      price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0   0  20141013  12.309987         3       1.00     7.074117  8.639588   \n",
       "1   1  20150225  12.100718         2       1.00     6.647688  9.210440   \n",
       "2   2  20150218  13.142168         3       2.00     7.427144  8.997271   \n",
       "3   3  20140627  12.458779         3       2.25     7.447751  8.827615   \n",
       "4   4  20150115  12.583999         3       1.50     6.966967  9.181118   \n",
       "\n",
       "   floors  waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "0     1.0           0     0          3      7    7.074117            0.0   \n",
       "1     1.0           0     0          3      6    6.647688            0.0   \n",
       "2     1.0           0     0          3      8    7.427144            0.0   \n",
       "3     2.0           0     0          3      7    7.447751            0.0   \n",
       "4     1.0           0     0          3      7    6.966967            0.0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1933             0    98028  47.7379 -122.233           2720   \n",
       "2      1987             0    98074  47.6168 -122.045           1800   \n",
       "3      1995             0    98003  47.3097 -122.327           2238   \n",
       "4      1963             0    98198  47.4095 -122.315           1650   \n",
       "\n",
       "   sqft_lot15  basement_present  renovated  \n",
       "0        5650                 0          0  \n",
       "1        8062                 0          0  \n",
       "2        7503                 0          0  \n",
       "3        6819                 0          0  \n",
       "4        9711                 0          0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- date는 yyyymmdd의 형태로 변형\n",
    "- sqft_basement는 지하실의 유무를 1과 0으로 변형\n",
    "- yr_renovated는 재건축 유무를 1과 0으로 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    # 방의 전체 갯수 \n",
    "    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
    "    \n",
    "    # 거실의 비율 \n",
    "    df['sqft_ratio'] = df['sqft_living'] / df['sqft_lot']\n",
    "    df['sqft_total_size'] = df['sqft_above'] + df['sqft_basement']\n",
    "    \n",
    "    # 면적 대비 거실의 비율 \n",
    "    df['sqft_ratio_1'] = df['sqft_living'] / df['sqft_total_size']\n",
    "    df['sqft_ratio15'] = df['sqft_living15'] / df['sqft_lot15'] \n",
    "    \n",
    "    df['date'] = df['date'].astype('int')\n",
    "df_train['per_price'] = df_train['price']/df_train['sqft_total_size']\n",
    "zipcode_price = df_train.groupby(['zipcode'])['per_price'].agg({'mean','var'}).reset_index()\n",
    "df_train = pd.merge(df_train,zipcode_price,how='left',on='zipcode')\n",
    "df_test = pd.merge(df_test,zipcode_price,how='left',on='zipcode')\n",
    "\n",
    "for df in [df_train,df_test]:\n",
    "    df['zipcode_mean'] = df['mean'] * df['sqft_total_size']\n",
    "    df['zipcode_var'] = df['var'] * df['sqft_total_size']\n",
    "    del df['mean']; del df['var']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 price 같은 경우는 비슷한 지역에 영향을 받아서 그것을 코드로 구현한 것임.\n",
    "- 주의해야 할 점은 단순 price가 아니라 평당 price를 써야 한다는 점임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Age of House\n",
    "\n",
    "- yr_built를 활용해 집의 나이 변수를 추가해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['age'] = 2015-df_train['yr_built']\n",
    "df_test['age'] = 2015-df_test['yr_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>basement_present</th>\n",
       "      <th>renovated</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>sqft_ratio</th>\n",
       "      <th>sqft_total_size</th>\n",
       "      <th>sqft_ratio_1</th>\n",
       "      <th>sqft_ratio15</th>\n",
       "      <th>per_price</th>\n",
       "      <th>zipcode_mean</th>\n",
       "      <th>zipcode_var</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20141013</td>\n",
       "      <td>12.309987</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.074117</td>\n",
       "      <td>8.639588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7.074117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.818803</td>\n",
       "      <td>7.074117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.237168</td>\n",
       "      <td>1.740145</td>\n",
       "      <td>9.368147</td>\n",
       "      <td>1.214207</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20150225</td>\n",
       "      <td>12.100718</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.647688</td>\n",
       "      <td>9.210440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6.647688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.721756</td>\n",
       "      <td>6.647688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.337385</td>\n",
       "      <td>1.820290</td>\n",
       "      <td>9.257745</td>\n",
       "      <td>1.023549</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20150218</td>\n",
       "      <td>13.142168</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.427144</td>\n",
       "      <td>8.997271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7.427144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.825489</td>\n",
       "      <td>7.427144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.239904</td>\n",
       "      <td>1.769478</td>\n",
       "      <td>11.307711</td>\n",
       "      <td>0.826257</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20140627</td>\n",
       "      <td>12.458779</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>7.447751</td>\n",
       "      <td>8.827615</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7.447751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.843688</td>\n",
       "      <td>7.447751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328201</td>\n",
       "      <td>1.672824</td>\n",
       "      <td>10.626177</td>\n",
       "      <td>1.012780</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20150115</td>\n",
       "      <td>12.583999</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>9.181118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.758837</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.169910</td>\n",
       "      <td>1.806238</td>\n",
       "      <td>10.032009</td>\n",
       "      <td>1.002206</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      date      price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0   0  20141013  12.309987         3       1.00     7.074117  8.639588   \n",
       "1   1  20150225  12.100718         2       1.00     6.647688  9.210440   \n",
       "2   2  20150218  13.142168         3       2.00     7.427144  8.997271   \n",
       "3   3  20140627  12.458779         3       2.25     7.447751  8.827615   \n",
       "4   4  20150115  12.583999         3       1.50     6.966967  9.181118   \n",
       "\n",
       "   floors  waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "0     1.0           0     0          3      7    7.074117            0.0   \n",
       "1     1.0           0     0          3      6    6.647688            0.0   \n",
       "2     1.0           0     0          3      8    7.427144            0.0   \n",
       "3     2.0           0     0          3      7    7.447751            0.0   \n",
       "4     1.0           0     0          3      7    6.966967            0.0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1933             0    98028  47.7379 -122.233           2720   \n",
       "2      1987             0    98074  47.6168 -122.045           1800   \n",
       "3      1995             0    98003  47.3097 -122.327           2238   \n",
       "4      1963             0    98198  47.4095 -122.315           1650   \n",
       "\n",
       "   sqft_lot15  basement_present  renovated  total_rooms  sqft_ratio  \\\n",
       "0        5650                 0          0         4.00    0.818803   \n",
       "1        8062                 0          0         3.00    0.721756   \n",
       "2        7503                 0          0         5.00    0.825489   \n",
       "3        6819                 0          0         5.25    0.843688   \n",
       "4        9711                 0          0         4.50    0.758837   \n",
       "\n",
       "   sqft_total_size  sqft_ratio_1  sqft_ratio15  per_price  zipcode_mean  \\\n",
       "0         7.074117           1.0      0.237168   1.740145      9.368147   \n",
       "1         6.647688           1.0      0.337385   1.820290      9.257745   \n",
       "2         7.427144           1.0      0.239904   1.769478     11.307711   \n",
       "3         7.447751           1.0      0.328201   1.672824     10.626177   \n",
       "4         6.966967           1.0      0.169910   1.806238     10.032009   \n",
       "\n",
       "   zipcode_var  age  \n",
       "0     1.214207   60  \n",
       "1     1.023549   82  \n",
       "2     0.826257   28  \n",
       "3     1.012780   20  \n",
       "4     1.002206   52  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링\n",
    "\n",
    "- 다양한 모델 참고 자료 \\ https://subinium.github.io/introduction-to-ensemble-1/#:~:text=%EC%95%99%EC%83%81%EB%B8%94(Ensemble)%20%ED%95%99%EC%8A%B5%EC%9D%80%20%EC%97%AC%EB%9F%AC,%EB%A5%BC%20%EA%B0%80%EC%A7%80%EA%B3%A0%20%EC%9D%B4%ED%95%B4%ED%95%98%EB%A9%B4%20%EC%A2%8B%EC%8A%B5%EB%8B%88%EB%8B%A4. \\ https://subinium.github.io/introduction-to-ensemble-2-boosting/\n",
    "\n",
    "(1) 단순 선형회귀(OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.791\n",
      "Model:                            OLS   Adj. R-squared:                  0.790\n",
      "Method:                 Least Squares   F-statistic:                     2178.\n",
      "Date:                Sun, 20 Feb 2022   Prob (F-statistic):               0.00\n",
      "Time:                        03:58:52   Log-Likelihood:                 39.002\n",
      "No. Observations:               15030   AIC:                            -24.00\n",
      "Df Residuals:                   15003   BIC:                             181.7\n",
      "Df Model:                          26                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "date              5.264e-06   4.47e-07     11.780      0.000    4.39e-06    6.14e-06\n",
      "bedrooms            -0.0319      0.003    -11.552      0.000      -0.037      -0.026\n",
      "bathrooms            0.0428      0.003     12.306      0.000       0.036       0.050\n",
      "sqft_living         -0.1122      0.044     -2.568      0.010      -0.198      -0.027\n",
      "sqft_lot             0.2097      0.020     10.404      0.000       0.170       0.249\n",
      "floors               0.0007      0.006      0.108      0.914      -0.012       0.013\n",
      "waterfront           0.4097      0.026     15.939      0.000       0.359       0.460\n",
      "view                 0.0642      0.003     20.725      0.000       0.058       0.070\n",
      "condition            0.0642      0.003     18.640      0.000       0.057       0.071\n",
      "grade                0.1493      0.003     48.429      0.000       0.143       0.155\n",
      "sqft_above           0.1867      0.021      9.064      0.000       0.146       0.227\n",
      "sqft_basement       -0.0516      0.012     -4.284      0.000      -0.075      -0.028\n",
      "yr_built            -0.0430      0.005     -8.578      0.000      -0.053      -0.033\n",
      "yr_renovated         0.0041      0.001      6.321      0.000       0.003       0.005\n",
      "zipcode             -0.0007   4.87e-05    -13.802      0.000      -0.001      -0.001\n",
      "lat                  1.3236      0.017     75.949      0.000       1.289       1.358\n",
      "long                 0.0803      0.023      3.463      0.001       0.035       0.126\n",
      "sqft_living15     9.362e-05   5.24e-06     17.872      0.000    8.34e-05       0.000\n",
      "sqft_lot15        2.386e-07   1.09e-07      2.183      0.029    2.44e-08    4.53e-07\n",
      "basement_present    -0.1519      0.179     -0.851      0.395      -0.502       0.198\n",
      "renovated           -8.1555      1.301     -6.267      0.000     -10.706      -5.604\n",
      "total_rooms          0.0109      0.002      6.341      0.000       0.008       0.014\n",
      "sqft_ratio           2.5157      0.244     10.309      0.000       2.037       2.994\n",
      "sqft_total_size      0.1351      0.013     10.195      0.000       0.109       0.161\n",
      "sqft_ratio_1        -0.3279      0.554     -0.592      0.554      -1.414       0.758\n",
      "sqft_ratio15         0.0751      0.019      3.985      0.000       0.038       0.112\n",
      "zipcode_mean        -0.0524      0.003    -19.605      0.000      -0.058      -0.047\n",
      "zipcode_var          0.0109      0.010      1.056      0.291      -0.009       0.031\n",
      "age                 -0.0395      0.005     -7.866      0.000      -0.049      -0.030\n",
      "==============================================================================\n",
      "Omnibus:                      270.413   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              557.135\n",
      "Skew:                           0.030   Prob(JB):                    1.05e-121\n",
      "Kurtosis:                       3.941   Cond. No.                     1.00e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 6.09e-14. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "train_columns = [c for c in df_train.columns if c not in ['id','price','per_price']]\n",
    "\n",
    "model = sm.OLS(df_train['price'].values, df_train[train_columns])\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adj. R-squared : 1.000 → 모델의 설명력이 약 100%라고 볼 수 있음.\n",
    "- 하지만 각각의 변수들 중에서는 p-value가 높은 값들이 있음을 확인할 수 있음.\n",
    "- 이에 대한 원인은 아래와 같이 생각해 볼 수 있음.\n",
    "  - FE해서 나온 파생변수들은 기존의 변수와 연관되어있음.\n",
    "  - sqft_로 시작하는 변수들끼리의 상관성\n",
    "- 따라서, 다중공선성의 문제를 가지기 때문으로 볼 수 있음..\n",
    "- 참고 : https://ysyblog.tistory.com/119 \\ https://learnx.tistory.com/entry/%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1Multicollinearity%EC%9D%B4%EB%9E%80 \\ https://bkshin.tistory.com/entry/DATA-20-%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1%EA%B3%BC-VIF \\ https://muzukphysics.tistory.com/entry/%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1-%ED%8C%90%EB%8B%A8-%EA%B8%B0%EC%A4%80-%EB%B0%8F-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95-VIF-%ED%99%95%EC%9D%B8-Multicollinea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중공선성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sqft_basement</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>total_rooms</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sqft_above</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sqft_total_size</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yr_built</td>\n",
       "      <td>2.535087e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>age</td>\n",
       "      <td>1.829421e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>yr_renovated</td>\n",
       "      <td>1.758191e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>renovated</td>\n",
       "      <td>1.758011e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sqft_ratio_1</td>\n",
       "      <td>6.752508e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>basement_present</td>\n",
       "      <td>2.035137e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>per_price</td>\n",
       "      <td>9.857457e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>1.823742e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sqft_ratio</td>\n",
       "      <td>9.800412e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>8.655963e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>zipcode_mean</td>\n",
       "      <td>3.414956e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>price</td>\n",
       "      <td>2.840327e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>zipcode_var</td>\n",
       "      <td>1.056963e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sqft_ratio15</td>\n",
       "      <td>4.639705e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>grade</td>\n",
       "      <td>3.934373e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>3.458720e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>floors</td>\n",
       "      <td>3.071450e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>long</td>\n",
       "      <td>2.786817e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sqft_lot15</td>\n",
       "      <td>2.371447e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lat</td>\n",
       "      <td>2.078459e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>zipcode</td>\n",
       "      <td>1.760760e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>view</td>\n",
       "      <td>1.493001e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>condition</td>\n",
       "      <td>1.310864e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>waterfront</td>\n",
       "      <td>1.224473e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>1.079577e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date</td>\n",
       "      <td>1.016517e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Features    VIF Values\n",
       "13     sqft_basement           inf\n",
       "4          bathrooms           inf\n",
       "23       total_rooms           inf\n",
       "12        sqft_above           inf\n",
       "25   sqft_total_size           inf\n",
       "3           bedrooms           inf\n",
       "14          yr_built  2.535087e+07\n",
       "31               age  1.829421e+04\n",
       "15      yr_renovated  1.758191e+04\n",
       "22         renovated  1.758011e+04\n",
       "26      sqft_ratio_1  6.752508e+03\n",
       "21  basement_present  2.035137e+03\n",
       "28         per_price  9.857457e+02\n",
       "5        sqft_living  1.823742e+02\n",
       "24        sqft_ratio  9.800412e+01\n",
       "6           sqft_lot  8.655963e+01\n",
       "29      zipcode_mean  3.414956e+01\n",
       "2              price  2.840327e+01\n",
       "30       zipcode_var  1.056963e+01\n",
       "27      sqft_ratio15  4.639705e+00\n",
       "11             grade  3.934373e+00\n",
       "19     sqft_living15  3.458720e+00\n",
       "7             floors  3.071450e+00\n",
       "18              long  2.786817e+00\n",
       "20        sqft_lot15  2.371447e+00\n",
       "17               lat  2.078459e+00\n",
       "16           zipcode  1.760760e+00\n",
       "9               view  1.493001e+00\n",
       "10         condition  1.310864e+00\n",
       "8         waterfront  1.224473e+00\n",
       "0                 id  1.079577e+00\n",
       "1               date  1.016517e+00"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "\n",
    "vif[\"Features\"] = df_train.columns\n",
    "vif[\"VIF Values\"] = [variance_inflation_factor(\n",
    "    df_train.values, i) for i in range(df_train.shape[1])]\n",
    "\n",
    "vif.sort_values(by='VIF Values',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 보통의 경우 10 이상이면 다중공선성이 존재한다고 말한다.\n",
    "- 위의 결과에서는 sqft_living15, floors, long, sqft_lot15, lat, zipcode, view, condition, waterfront, date 변수를 제외한 모든 변수들에서 다중공선성이 존재하는 문제점이 있다.\n",
    "- sqft_로 시작하는 변수들끼리의 상관성이 영향이 꽤 있다 판단되므로 sqft_로 시작하는 일부 변를 삭제한다.\n",
    "- 그 외 독립변수 사이 상관관계가 있어 보이는 변수들은 삭제한다.\n",
    "- sqft_living, yr_built, zipcode_mean, zipcode_var, yr_renovated, per_price 삭제\n",
    "\n",
    "#### 변수삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'price', 'bedrooms', 'bathrooms', 'sqft_lot', 'floors',\n",
      "       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
      "       'sqft_basement', 'zipcode', 'lat', 'long', 'sqft_living15',\n",
      "       'sqft_lot15', 'basement_present', 'renovated', 'total_rooms',\n",
      "       'sqft_ratio', 'sqft_total_size', 'sqft_ratio_1', 'sqft_ratio15', 'age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "del df_train['sqft_living']\n",
    "del df_train['yr_built']\n",
    "del df_train['zipcode_mean']\n",
    "del df_train['zipcode_var']\n",
    "del df_train['yr_renovated']\n",
    "del df_train['per_price']\n",
    "del df_train['id']\n",
    "\n",
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'bedrooms', 'bathrooms', 'sqft_lot', 'floors', 'waterfront',\n",
      "       'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'zipcode',\n",
      "       'lat', 'long', 'sqft_living15', 'sqft_lot15', 'basement_present',\n",
      "       'renovated', 'total_rooms', 'sqft_ratio', 'sqft_total_size',\n",
      "       'sqft_ratio_1', 'sqft_ratio15', 'age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "del df_test['sqft_living']\n",
    "del df_test['yr_built']\n",
    "del df_test['zipcode_mean']\n",
    "del df_test['zipcode_var']\n",
    "del df_test['yr_renovated']\n",
    "del df_test['id']\n",
    "\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['price']\n",
    "del df_train['price']\n",
    "\n",
    "train = df_train\n",
    "test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "-  모델 하이퍼파라미터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=2022     # 하지만 우리는 이렇게 고정값을 세팅해 두겠습니다. \n",
    "\n",
    "rdforest = RandomForestRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5):\n",
    "    # GridSearchCV 모델로 초기화\n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, scoring='neg_mean_squared_error', \\\n",
    "                              cv=5, verbose=verbose, n_jobs=n_jobs)\n",
    "    \n",
    "    # 모델 fitting\n",
    "    grid_model.fit(train, y)\n",
    "\n",
    "    # 결과값 저장\n",
    "    params = grid_model.cv_results_['params']\n",
    "    score = grid_model.cv_results_['mean_test_score']\n",
    "    \n",
    "    # 데이터 프레임 생성\n",
    "    results = pd.DataFrame(params)\n",
    "    results['score'] = score\n",
    "    \n",
    "    # RMSLE 값 계산 후 정렬\n",
    "    results['RMSLE'] = np.sqrt(-1 * results['score'])\n",
    "    results = results.sort_values('RMSLE')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>score</th>\n",
       "      <th>RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.032972</td>\n",
       "      <td>0.181582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.032972</td>\n",
       "      <td>0.181582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>0.183285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.033593</td>\n",
       "      <td>0.183285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.036060</td>\n",
       "      <td>0.189896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.036060</td>\n",
       "      <td>0.189896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046552</td>\n",
       "      <td>0.215758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.046552</td>\n",
       "      <td>0.215758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators bootstrap     score     RMSLE\n",
       "3            60       NaN -0.032972  0.181582\n",
       "7            60      True -0.032972  0.181582\n",
       "2            30       NaN -0.033593  0.183285\n",
       "6            30      True -0.033593  0.183285\n",
       "1            10       NaN -0.036060  0.189896\n",
       "5            10      True -0.036060  0.189896\n",
       "0             3       NaN -0.046552  0.215758\n",
       "4             3      True -0.046552  0.215758"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30, 60]},\n",
    "    {'bootstrap': [True], 'n_estimators': [3, 10, 30, 60]},\n",
    "]\n",
    "\n",
    "model = RandomForestRegressor(random_state=random_state)\n",
    "my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.86750496, 13.10749021, 14.00170219, ..., 13.03954511,\n",
       "       12.67583263, 13.10158444])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=3)\n",
    "model.fit(train, y)\n",
    "prediction = model.predict(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델의 학습 및 예측\n",
    "\n",
    "###### 모델 별 Validation 및 모델 학습 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................................n_estimators=3; total time=   0.7s\n",
      "[CV] END ....................................n_estimators=10; total time=   2.3s\n",
      "[CV] END ....................................n_estimators=30; total time=   6.9s\n",
      "[CV] END ....................................n_estimators=60; total time=  20.7s\n",
      "[CV] END ....................bootstrap=True, n_estimators=10; total time=   3.6s\n",
      "[CV] END ....................bootstrap=True, n_estimators=30; total time=   7.1s\n",
      "[CV] END ....................bootstrap=True, n_estimators=60; total time=  14.4s\n",
      "[CV] END .....................................n_estimators=3; total time=   1.3s\n",
      "[CV] END ....................................n_estimators=10; total time=   4.6s\n",
      "[CV] END ....................................n_estimators=30; total time=   7.8s\n",
      "[CV] END ....................................n_estimators=60; total time=  15.2s\n",
      "[CV] END .....................bootstrap=True, n_estimators=3; total time=   0.7s\n",
      "[CV] END .....................bootstrap=True, n_estimators=3; total time=   1.0s\n",
      "[CV] END ....................bootstrap=True, n_estimators=10; total time=   2.3s\n",
      "[CV] END ....................bootstrap=True, n_estimators=30; total time=   7.0s\n",
      "[CV] END ....................bootstrap=True, n_estimators=60; total time=  16.1s\n",
      "[CV] END .....................................n_estimators=3; total time=   0.7s\n",
      "[CV] END ....................................n_estimators=10; total time=   2.6s\n",
      "[CV] END ....................................n_estimators=30; total time=   9.1s\n",
      "[CV] END ....................................n_estimators=60; total time=  14.9s\n",
      "[CV] END .....................bootstrap=True, n_estimators=3; total time=   0.7s\n",
      "[CV] END .....................bootstrap=True, n_estimators=3; total time=   0.9s\n",
      "[CV] END .....................bootstrap=True, n_estimators=3; total time=   1.0s\n",
      "[CV] END ....................bootstrap=True, n_estimators=10; total time=   2.3s\n",
      "[CV] END ....................bootstrap=True, n_estimators=30; total time=   7.0s\n",
      "[CV] END ....................bootstrap=True, n_estimators=60; total time=  17.6s\n",
      "[CV] END .....................................n_estimators=3; total time=   0.7s\n",
      "[CV] END ....................................n_estimators=10; total time=   2.2s\n",
      "[CV] END ....................................n_estimators=30; total time=   8.5s\n",
      "[CV] END ....................................n_estimators=60; total time=  19.1s\n",
      "[CV] END ....................bootstrap=True, n_estimators=10; total time=   3.1s\n",
      "[CV] END ....................bootstrap=True, n_estimators=30; total time=  11.2s\n",
      "[CV] END ....................bootstrap=True, n_estimators=60; total time=  13.5s\n",
      "[CV] END .....................................n_estimators=3; total time=   1.3s\n",
      "[CV] END ....................................n_estimators=10; total time=   3.9s\n",
      "[CV] END ....................................n_estimators=30; total time=  11.7s\n",
      "[CV] END ....................................n_estimators=60; total time=  15.3s\n",
      "[CV] END ....................bootstrap=True, n_estimators=10; total time=   4.2s\n",
      "[CV] END ....................bootstrap=True, n_estimators=30; total time=  10.1s\n",
      "[CV] END ....................bootstrap=True, n_estimators=60; total time=  14.0s\n",
      "\n",
      "GradientBoostingRegressor score: 0.1600 (0.0091)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "score = rmsle_cv(model_gbr)\n",
    "print(\"\\nGradientBoostingRegressor score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:15:28] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:15:40] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:15:53] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:16:05] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:16:17] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:16:30] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:16:42] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:16:54] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:17:06] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:17:19] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\n",
      "XGBRegressor score: 0.1605 (0.0090)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_xgb = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"\\nXGBRegressor score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) LGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "\n",
      "XGBRegressor score: 0.1775 (0.0058)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"\\nXGBRegressor score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForestRegressor score: 0.2130 (0.0056)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(n_estimators=3)\n",
    "score = rmsle_cv(model_rf)\n",
    "print(\"\\nRandomForestRegressor score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4941548\ttotal: 48.4ms\tremaining: 48.3s\n",
      "50:\tlearn: 0.2040573\ttotal: 116ms\tremaining: 2.17s\n",
      "100:\tlearn: 0.1831508\ttotal: 183ms\tremaining: 1.63s\n",
      "150:\tlearn: 0.1730019\ttotal: 251ms\tremaining: 1.41s\n",
      "200:\tlearn: 0.1677444\ttotal: 320ms\tremaining: 1.27s\n",
      "250:\tlearn: 0.1636735\ttotal: 388ms\tremaining: 1.16s\n",
      "300:\tlearn: 0.1603651\ttotal: 455ms\tremaining: 1.06s\n",
      "350:\tlearn: 0.1577234\ttotal: 523ms\tremaining: 966ms\n",
      "400:\tlearn: 0.1554718\ttotal: 591ms\tremaining: 882ms\n",
      "450:\tlearn: 0.1534749\ttotal: 663ms\tremaining: 807ms\n",
      "500:\tlearn: 0.1519879\ttotal: 734ms\tremaining: 731ms\n",
      "550:\tlearn: 0.1506550\ttotal: 804ms\tremaining: 655ms\n",
      "600:\tlearn: 0.1491562\ttotal: 874ms\tremaining: 580ms\n",
      "650:\tlearn: 0.1477925\ttotal: 944ms\tremaining: 506ms\n",
      "700:\tlearn: 0.1467116\ttotal: 1.01s\tremaining: 431ms\n",
      "750:\tlearn: 0.1455793\ttotal: 1.08s\tremaining: 358ms\n",
      "800:\tlearn: 0.1444618\ttotal: 1.15s\tremaining: 285ms\n",
      "850:\tlearn: 0.1433897\ttotal: 1.22s\tremaining: 213ms\n",
      "900:\tlearn: 0.1423457\ttotal: 1.28s\tremaining: 141ms\n",
      "950:\tlearn: 0.1414849\ttotal: 1.36s\tremaining: 70.2ms\n",
      "999:\tlearn: 0.1404119\ttotal: 1.43s\tremaining: 0us\n",
      "0:\tlearn: 0.4934555\ttotal: 1.91ms\tremaining: 1.91s\n",
      "50:\tlearn: 0.2055511\ttotal: 71.2ms\tremaining: 1.32s\n",
      "100:\tlearn: 0.1846111\ttotal: 140ms\tremaining: 1.24s\n",
      "150:\tlearn: 0.1728737\ttotal: 209ms\tremaining: 1.18s\n",
      "200:\tlearn: 0.1671406\ttotal: 286ms\tremaining: 1.14s\n",
      "250:\tlearn: 0.1626031\ttotal: 356ms\tremaining: 1.06s\n",
      "300:\tlearn: 0.1595036\ttotal: 427ms\tremaining: 991ms\n",
      "350:\tlearn: 0.1569618\ttotal: 498ms\tremaining: 920ms\n",
      "400:\tlearn: 0.1547622\ttotal: 565ms\tremaining: 843ms\n",
      "450:\tlearn: 0.1524923\ttotal: 634ms\tremaining: 771ms\n",
      "500:\tlearn: 0.1507256\ttotal: 702ms\tremaining: 699ms\n",
      "550:\tlearn: 0.1491861\ttotal: 768ms\tremaining: 625ms\n",
      "600:\tlearn: 0.1477699\ttotal: 838ms\tremaining: 557ms\n",
      "650:\tlearn: 0.1465209\ttotal: 908ms\tremaining: 487ms\n",
      "700:\tlearn: 0.1453252\ttotal: 991ms\tremaining: 423ms\n",
      "750:\tlearn: 0.1441921\ttotal: 1.08s\tremaining: 357ms\n",
      "800:\tlearn: 0.1430539\ttotal: 1.16s\tremaining: 289ms\n",
      "850:\tlearn: 0.1419685\ttotal: 1.25s\tremaining: 219ms\n",
      "900:\tlearn: 0.1409076\ttotal: 1.33s\tremaining: 146ms\n",
      "950:\tlearn: 0.1398761\ttotal: 1.4s\tremaining: 72.1ms\n",
      "999:\tlearn: 0.1389766\ttotal: 1.47s\tremaining: 0us\n",
      "0:\tlearn: 0.4956411\ttotal: 1.81ms\tremaining: 1.81s\n",
      "50:\tlearn: 0.2039849\ttotal: 76.7ms\tremaining: 1.43s\n",
      "100:\tlearn: 0.1832840\ttotal: 154ms\tremaining: 1.37s\n",
      "150:\tlearn: 0.1730716\ttotal: 228ms\tremaining: 1.28s\n",
      "200:\tlearn: 0.1671152\ttotal: 300ms\tremaining: 1.19s\n",
      "250:\tlearn: 0.1631973\ttotal: 373ms\tremaining: 1.11s\n",
      "300:\tlearn: 0.1600799\ttotal: 445ms\tremaining: 1.03s\n",
      "350:\tlearn: 0.1578233\ttotal: 515ms\tremaining: 953ms\n",
      "400:\tlearn: 0.1558217\ttotal: 589ms\tremaining: 880ms\n",
      "450:\tlearn: 0.1537852\ttotal: 659ms\tremaining: 802ms\n",
      "500:\tlearn: 0.1518704\ttotal: 732ms\tremaining: 729ms\n",
      "550:\tlearn: 0.1504163\ttotal: 802ms\tremaining: 654ms\n",
      "600:\tlearn: 0.1487618\ttotal: 872ms\tremaining: 579ms\n",
      "650:\tlearn: 0.1473294\ttotal: 940ms\tremaining: 504ms\n",
      "700:\tlearn: 0.1461009\ttotal: 1.01s\tremaining: 431ms\n",
      "750:\tlearn: 0.1449953\ttotal: 1.08s\tremaining: 359ms\n",
      "800:\tlearn: 0.1437580\ttotal: 1.15s\tremaining: 286ms\n",
      "850:\tlearn: 0.1427434\ttotal: 1.22s\tremaining: 213ms\n",
      "900:\tlearn: 0.1416975\ttotal: 1.28s\tremaining: 141ms\n",
      "950:\tlearn: 0.1407411\ttotal: 1.35s\tremaining: 69.7ms\n",
      "999:\tlearn: 0.1397150\ttotal: 1.42s\tremaining: 0us\n",
      "0:\tlearn: 0.4940874\ttotal: 1.61ms\tremaining: 1.61s\n",
      "50:\tlearn: 0.2036727\ttotal: 70.5ms\tremaining: 1.31s\n",
      "100:\tlearn: 0.1834860\ttotal: 137ms\tremaining: 1.22s\n",
      "150:\tlearn: 0.1729117\ttotal: 212ms\tremaining: 1.19s\n",
      "200:\tlearn: 0.1671859\ttotal: 278ms\tremaining: 1.11s\n",
      "250:\tlearn: 0.1626949\ttotal: 349ms\tremaining: 1.04s\n",
      "300:\tlearn: 0.1596884\ttotal: 418ms\tremaining: 970ms\n",
      "350:\tlearn: 0.1569063\ttotal: 487ms\tremaining: 901ms\n",
      "400:\tlearn: 0.1548060\ttotal: 559ms\tremaining: 835ms\n",
      "450:\tlearn: 0.1530102\ttotal: 635ms\tremaining: 773ms\n",
      "500:\tlearn: 0.1515955\ttotal: 709ms\tremaining: 706ms\n",
      "550:\tlearn: 0.1499901\ttotal: 784ms\tremaining: 639ms\n",
      "600:\tlearn: 0.1484127\ttotal: 858ms\tremaining: 570ms\n",
      "650:\tlearn: 0.1470154\ttotal: 930ms\tremaining: 498ms\n",
      "700:\tlearn: 0.1458515\ttotal: 1.01s\tremaining: 432ms\n",
      "750:\tlearn: 0.1446574\ttotal: 1.08s\tremaining: 360ms\n",
      "800:\tlearn: 0.1434251\ttotal: 1.15s\tremaining: 287ms\n",
      "850:\tlearn: 0.1424239\ttotal: 1.23s\tremaining: 215ms\n",
      "900:\tlearn: 0.1413206\ttotal: 1.3s\tremaining: 142ms\n",
      "950:\tlearn: 0.1403152\ttotal: 1.37s\tremaining: 70.5ms\n",
      "999:\tlearn: 0.1394351\ttotal: 1.44s\tremaining: 0us\n",
      "0:\tlearn: 0.4965179\ttotal: 2.09ms\tremaining: 2.09s\n",
      "50:\tlearn: 0.2031492\ttotal: 79ms\tremaining: 1.47s\n",
      "100:\tlearn: 0.1826812\ttotal: 151ms\tremaining: 1.34s\n",
      "150:\tlearn: 0.1733047\ttotal: 221ms\tremaining: 1.24s\n",
      "200:\tlearn: 0.1667264\ttotal: 292ms\tremaining: 1.16s\n",
      "250:\tlearn: 0.1632513\ttotal: 361ms\tremaining: 1.08s\n",
      "300:\tlearn: 0.1599483\ttotal: 433ms\tremaining: 1s\n",
      "350:\tlearn: 0.1578162\ttotal: 506ms\tremaining: 936ms\n",
      "400:\tlearn: 0.1555169\ttotal: 578ms\tremaining: 864ms\n",
      "450:\tlearn: 0.1536972\ttotal: 651ms\tremaining: 793ms\n",
      "500:\tlearn: 0.1520953\ttotal: 723ms\tremaining: 720ms\n",
      "550:\tlearn: 0.1503887\ttotal: 796ms\tremaining: 648ms\n",
      "600:\tlearn: 0.1488806\ttotal: 870ms\tremaining: 577ms\n",
      "650:\tlearn: 0.1475849\ttotal: 941ms\tremaining: 505ms\n",
      "700:\tlearn: 0.1462024\ttotal: 1.01s\tremaining: 433ms\n",
      "750:\tlearn: 0.1451126\ttotal: 1.09s\tremaining: 361ms\n",
      "800:\tlearn: 0.1440372\ttotal: 1.16s\tremaining: 288ms\n",
      "850:\tlearn: 0.1429720\ttotal: 1.23s\tremaining: 216ms\n",
      "900:\tlearn: 0.1419336\ttotal: 1.3s\tremaining: 143ms\n",
      "950:\tlearn: 0.1409343\ttotal: 1.37s\tremaining: 70.8ms\n",
      "999:\tlearn: 0.1400304\ttotal: 1.45s\tremaining: 0us\n",
      "0:\tlearn: 0.4942889\ttotal: 1.85ms\tremaining: 1.85s\n",
      "50:\tlearn: 0.2034199\ttotal: 75.7ms\tremaining: 1.41s\n",
      "100:\tlearn: 0.1818778\ttotal: 147ms\tremaining: 1.31s\n",
      "150:\tlearn: 0.1723818\ttotal: 217ms\tremaining: 1.22s\n",
      "200:\tlearn: 0.1662598\ttotal: 288ms\tremaining: 1.14s\n",
      "250:\tlearn: 0.1625017\ttotal: 357ms\tremaining: 1.06s\n",
      "300:\tlearn: 0.1589938\ttotal: 429ms\tremaining: 996ms\n",
      "350:\tlearn: 0.1563053\ttotal: 499ms\tremaining: 923ms\n",
      "400:\tlearn: 0.1541419\ttotal: 571ms\tremaining: 853ms\n",
      "450:\tlearn: 0.1523463\ttotal: 640ms\tremaining: 779ms\n",
      "500:\tlearn: 0.1505286\ttotal: 710ms\tremaining: 707ms\n",
      "550:\tlearn: 0.1492499\ttotal: 780ms\tremaining: 635ms\n",
      "600:\tlearn: 0.1480498\ttotal: 849ms\tremaining: 564ms\n",
      "650:\tlearn: 0.1467889\ttotal: 920ms\tremaining: 493ms\n",
      "700:\tlearn: 0.1456378\ttotal: 990ms\tremaining: 422ms\n",
      "750:\tlearn: 0.1443830\ttotal: 1.06s\tremaining: 352ms\n",
      "800:\tlearn: 0.1432643\ttotal: 1.13s\tremaining: 281ms\n",
      "850:\tlearn: 0.1420956\ttotal: 1.2s\tremaining: 210ms\n",
      "900:\tlearn: 0.1410189\ttotal: 1.27s\tremaining: 140ms\n",
      "950:\tlearn: 0.1399952\ttotal: 1.35s\tremaining: 69.4ms\n",
      "999:\tlearn: 0.1389102\ttotal: 1.42s\tremaining: 0us\n",
      "0:\tlearn: 0.4945843\ttotal: 1.52ms\tremaining: 1.52s\n",
      "50:\tlearn: 0.2020094\ttotal: 73.8ms\tremaining: 1.37s\n",
      "100:\tlearn: 0.1830700\ttotal: 142ms\tremaining: 1.27s\n",
      "150:\tlearn: 0.1725240\ttotal: 220ms\tremaining: 1.24s\n",
      "200:\tlearn: 0.1670170\ttotal: 293ms\tremaining: 1.16s\n",
      "250:\tlearn: 0.1627875\ttotal: 363ms\tremaining: 1.08s\n",
      "300:\tlearn: 0.1596124\ttotal: 435ms\tremaining: 1.01s\n",
      "350:\tlearn: 0.1569739\ttotal: 509ms\tremaining: 940ms\n",
      "400:\tlearn: 0.1546471\ttotal: 583ms\tremaining: 871ms\n",
      "450:\tlearn: 0.1531220\ttotal: 656ms\tremaining: 798ms\n",
      "500:\tlearn: 0.1514509\ttotal: 728ms\tremaining: 725ms\n",
      "550:\tlearn: 0.1500652\ttotal: 802ms\tremaining: 653ms\n",
      "600:\tlearn: 0.1486775\ttotal: 878ms\tremaining: 583ms\n",
      "650:\tlearn: 0.1472665\ttotal: 950ms\tremaining: 509ms\n",
      "700:\tlearn: 0.1460838\ttotal: 1.02s\tremaining: 435ms\n",
      "750:\tlearn: 0.1450575\ttotal: 1.09s\tremaining: 363ms\n",
      "800:\tlearn: 0.1437822\ttotal: 1.16s\tremaining: 289ms\n",
      "850:\tlearn: 0.1427215\ttotal: 1.23s\tremaining: 216ms\n",
      "900:\tlearn: 0.1416803\ttotal: 1.31s\tremaining: 144ms\n",
      "950:\tlearn: 0.1405545\ttotal: 1.39s\tremaining: 71.6ms\n",
      "999:\tlearn: 0.1396696\ttotal: 1.46s\tremaining: 0us\n",
      "0:\tlearn: 0.4942337\ttotal: 1.78ms\tremaining: 1.77s\n",
      "50:\tlearn: 0.2015752\ttotal: 75.3ms\tremaining: 1.4s\n",
      "100:\tlearn: 0.1810339\ttotal: 149ms\tremaining: 1.32s\n",
      "150:\tlearn: 0.1718403\ttotal: 220ms\tremaining: 1.24s\n",
      "200:\tlearn: 0.1660674\ttotal: 291ms\tremaining: 1.16s\n",
      "250:\tlearn: 0.1622506\ttotal: 365ms\tremaining: 1.09s\n",
      "300:\tlearn: 0.1594960\ttotal: 439ms\tremaining: 1.02s\n",
      "350:\tlearn: 0.1568370\ttotal: 511ms\tremaining: 946ms\n",
      "400:\tlearn: 0.1547628\ttotal: 582ms\tremaining: 870ms\n",
      "450:\tlearn: 0.1528624\ttotal: 655ms\tremaining: 797ms\n",
      "500:\tlearn: 0.1513865\ttotal: 728ms\tremaining: 725ms\n",
      "550:\tlearn: 0.1498608\ttotal: 801ms\tremaining: 653ms\n",
      "600:\tlearn: 0.1486086\ttotal: 872ms\tremaining: 579ms\n",
      "650:\tlearn: 0.1474782\ttotal: 945ms\tremaining: 507ms\n",
      "700:\tlearn: 0.1463496\ttotal: 1.02s\tremaining: 434ms\n",
      "750:\tlearn: 0.1452082\ttotal: 1.09s\tremaining: 362ms\n",
      "800:\tlearn: 0.1440580\ttotal: 1.16s\tremaining: 289ms\n",
      "850:\tlearn: 0.1429743\ttotal: 1.23s\tremaining: 216ms\n",
      "900:\tlearn: 0.1420636\ttotal: 1.31s\tremaining: 144ms\n",
      "950:\tlearn: 0.1410343\ttotal: 1.38s\tremaining: 71.1ms\n",
      "999:\tlearn: 0.1401183\ttotal: 1.45s\tremaining: 0us\n",
      "0:\tlearn: 0.4948679\ttotal: 2.14ms\tremaining: 2.14s\n",
      "50:\tlearn: 0.2038306\ttotal: 93.9ms\tremaining: 1.75s\n",
      "100:\tlearn: 0.1838983\ttotal: 177ms\tremaining: 1.58s\n",
      "150:\tlearn: 0.1731489\ttotal: 258ms\tremaining: 1.45s\n",
      "200:\tlearn: 0.1672204\ttotal: 332ms\tremaining: 1.32s\n",
      "250:\tlearn: 0.1630714\ttotal: 406ms\tremaining: 1.21s\n",
      "300:\tlearn: 0.1597279\ttotal: 478ms\tremaining: 1.11s\n",
      "350:\tlearn: 0.1569650\ttotal: 551ms\tremaining: 1.02s\n",
      "400:\tlearn: 0.1549207\ttotal: 623ms\tremaining: 930ms\n",
      "450:\tlearn: 0.1528360\ttotal: 693ms\tremaining: 843ms\n",
      "500:\tlearn: 0.1510950\ttotal: 763ms\tremaining: 760ms\n",
      "550:\tlearn: 0.1496617\ttotal: 834ms\tremaining: 680ms\n",
      "600:\tlearn: 0.1481849\ttotal: 902ms\tremaining: 599ms\n",
      "650:\tlearn: 0.1468629\ttotal: 973ms\tremaining: 522ms\n",
      "700:\tlearn: 0.1455986\ttotal: 1.05s\tremaining: 446ms\n",
      "750:\tlearn: 0.1444687\ttotal: 1.12s\tremaining: 371ms\n",
      "800:\tlearn: 0.1433583\ttotal: 1.19s\tremaining: 295ms\n",
      "850:\tlearn: 0.1423197\ttotal: 1.26s\tremaining: 221ms\n",
      "900:\tlearn: 0.1414858\ttotal: 1.33s\tremaining: 146ms\n",
      "950:\tlearn: 0.1404774\ttotal: 1.4s\tremaining: 72.3ms\n",
      "999:\tlearn: 0.1396009\ttotal: 1.48s\tremaining: 0us\n",
      "0:\tlearn: 0.4979875\ttotal: 1.74ms\tremaining: 1.74s\n",
      "50:\tlearn: 0.2048925\ttotal: 76.1ms\tremaining: 1.42s\n",
      "100:\tlearn: 0.1855012\ttotal: 149ms\tremaining: 1.32s\n",
      "150:\tlearn: 0.1750697\ttotal: 218ms\tremaining: 1.23s\n",
      "200:\tlearn: 0.1697694\ttotal: 291ms\tremaining: 1.16s\n",
      "250:\tlearn: 0.1656548\ttotal: 361ms\tremaining: 1.08s\n",
      "300:\tlearn: 0.1629136\ttotal: 432ms\tremaining: 1s\n",
      "350:\tlearn: 0.1604057\ttotal: 500ms\tremaining: 924ms\n",
      "400:\tlearn: 0.1584820\ttotal: 568ms\tremaining: 849ms\n",
      "450:\tlearn: 0.1564973\ttotal: 637ms\tremaining: 775ms\n",
      "500:\tlearn: 0.1549120\ttotal: 704ms\tremaining: 701ms\n",
      "550:\tlearn: 0.1532402\ttotal: 774ms\tremaining: 631ms\n",
      "600:\tlearn: 0.1518583\ttotal: 847ms\tremaining: 562ms\n",
      "650:\tlearn: 0.1504891\ttotal: 915ms\tremaining: 491ms\n",
      "700:\tlearn: 0.1491064\ttotal: 984ms\tremaining: 420ms\n",
      "750:\tlearn: 0.1479746\ttotal: 1.06s\tremaining: 350ms\n",
      "800:\tlearn: 0.1468782\ttotal: 1.13s\tremaining: 280ms\n",
      "850:\tlearn: 0.1457557\ttotal: 1.2s\tremaining: 209ms\n",
      "900:\tlearn: 0.1448142\ttotal: 1.27s\tremaining: 139ms\n",
      "950:\tlearn: 0.1438465\ttotal: 1.34s\tremaining: 69.2ms\n",
      "999:\tlearn: 0.1429585\ttotal: 1.43s\tremaining: 0us\n",
      "\n",
      "CatBoostRegressor score: 0.1599 (0.0090)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_cb = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=4, l2_leaf_reg=20, \n",
    "                             bootstrap_type='Bernoulli', subsample=0.6, eval_metric='RMSE', \n",
    "                             metric_period=50, od_type='Iter', od_wait=45, random_seed=17, allow_writing_files=False)\n",
    "score = rmsle_cv(model_cb)\n",
    "print(\"\\nCatBoostRegressor score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 별 예측\n",
    "\n",
    "- RMSE (Root-Mean-Square Error)\n",
    "  - 잔차(예측 오차)의 표준편차. 잔차는 회쉬선 데이터 포인트에서 얼마나 멀리 떨어져 있는지 측정함. RMSE는 이러한 잔차가 얼나마 분산되어 있는지 측정하는데 즉, 데이터가 가장 적합한 선 주위에 얼마나 집중되어 있는지 알려줌.\n",
    "  - 값이 작을수록 정밀도가 높음.\n",
    "  - 모델 또는 추정자가 예측한 값 (샘플 또는 모집단 값)과 관찰된 값 간의 차이를 측정하는데 자주 사용됨.\n",
    "  - 주로 회귀분석에서 이격도를 확인하는데 주로 사용하는데, 비선형적인 방법을 통한 검증에는 주로 활용되지는 않는 편이나 쓸 수는 있음.\n",
    "  - 에러가 예측하려는 값의 크기에 의존적이라는 면에서 RMSE는 크기 의존적 에러(Scale-dependent Errors)에 속함.\n",
    "- 참고 : https://koreapy.tistory.com/529 \\ https://brunch.co.kr/@chris-song/34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred): \n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11239171398239439\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingRegressor\n",
    "model_gbr.fit(train, y)\n",
    "train_pred = model_gbr.predict(train)\n",
    "gbr_pred = np.expm1(model_gbr.predict(test))\n",
    "print(rmsle(y, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:19:09] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "0.12969515056025335\n"
     ]
    }
   ],
   "source": [
    "# XGBRegressor\n",
    "model_xgb.fit(train, y)\n",
    "train_pred = model_xgb.predict(train)\n",
    "xgb_pred = np.expm1(model_xgb.predict(test))\n",
    "print(rmsle(y, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "0.16847294062632265\n"
     ]
    }
   ],
   "source": [
    "# LGBRegressor\n",
    "model_lgb.fit(train, y)\n",
    "train_pred = model_lgb.predict(train)\n",
    "lgb_pred = np.expm1(model_lgb.predict(test))\n",
    "print(rmsle(y, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10740814007967998\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor\n",
    "model_rf.fit(train, y)\n",
    "train_pred = model_rf.predict(train)\n",
    "rf_pred = np.expm1(model_rf.predict(test))\n",
    "print(rmsle(y, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4966765\ttotal: 1.98ms\tremaining: 1.98s\n",
      "50:\tlearn: 0.2035899\ttotal: 78.4ms\tremaining: 1.46s\n",
      "100:\tlearn: 0.1834158\ttotal: 156ms\tremaining: 1.39s\n",
      "150:\tlearn: 0.1726069\ttotal: 232ms\tremaining: 1.31s\n",
      "200:\tlearn: 0.1674069\ttotal: 307ms\tremaining: 1.22s\n",
      "250:\tlearn: 0.1637388\ttotal: 379ms\tremaining: 1.13s\n",
      "300:\tlearn: 0.1603589\ttotal: 455ms\tremaining: 1.06s\n",
      "350:\tlearn: 0.1577469\ttotal: 533ms\tremaining: 985ms\n",
      "400:\tlearn: 0.1558125\ttotal: 608ms\tremaining: 909ms\n",
      "450:\tlearn: 0.1537268\ttotal: 691ms\tremaining: 841ms\n",
      "500:\tlearn: 0.1521217\ttotal: 770ms\tremaining: 767ms\n",
      "550:\tlearn: 0.1508564\ttotal: 846ms\tremaining: 690ms\n",
      "600:\tlearn: 0.1496237\ttotal: 923ms\tremaining: 613ms\n",
      "650:\tlearn: 0.1481826\ttotal: 1s\tremaining: 536ms\n",
      "700:\tlearn: 0.1471894\ttotal: 1.08s\tremaining: 459ms\n",
      "750:\tlearn: 0.1461014\ttotal: 1.16s\tremaining: 384ms\n",
      "800:\tlearn: 0.1449344\ttotal: 1.23s\tremaining: 307ms\n",
      "850:\tlearn: 0.1438446\ttotal: 1.31s\tremaining: 229ms\n",
      "900:\tlearn: 0.1428966\ttotal: 1.38s\tremaining: 152ms\n",
      "950:\tlearn: 0.1419590\ttotal: 1.46s\tremaining: 75ms\n",
      "999:\tlearn: 0.1410020\ttotal: 1.53s\tremaining: 0us\n",
      "0.1410019663622063\n"
     ]
    }
   ],
   "source": [
    "# CatBoostRegressor\n",
    "model_cb.fit(train, y)\n",
    "train_pred = model_cb.predict(train)\n",
    "cb_pred = np.expm1(model_cb.predict(test))\n",
    "print(rmsle(y, train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged base models class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:20:19] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[04:21:25] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[04:22:31] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[04:23:37] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[04:24:43] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[04:25:49] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[04:26:55] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[04:28:01] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[04:29:07] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[04:30:13] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      " Averaged base models score: 0.1633 (0.0077)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (model_gbr, model_xgb, model_lgb, model_rf))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackingAveragedModels\n",
    "\n",
    "- 기반모델 : GradientBoostingRegressor, XGBRegressor, LGBRegressor, RandomForestRegressor\n",
    "- 메타모델 : CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (model_gbr, model_xgb, model_lgb, model_rf),\n",
    "                                                 meta_model = model_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:34:27] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:34:38] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:34:49] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:35:01] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:35:12] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "0:\tlearn: 0.4851350\ttotal: 1.22ms\tremaining: 1.22s\n",
      "50:\tlearn: 0.1621277\ttotal: 44.3ms\tremaining: 825ms\n",
      "100:\tlearn: 0.1609814\ttotal: 86.3ms\tremaining: 768ms\n",
      "150:\tlearn: 0.1599891\ttotal: 130ms\tremaining: 732ms\n",
      "200:\tlearn: 0.1592520\ttotal: 172ms\tremaining: 685ms\n",
      "250:\tlearn: 0.1585881\ttotal: 214ms\tremaining: 638ms\n",
      "300:\tlearn: 0.1580222\ttotal: 256ms\tremaining: 594ms\n",
      "350:\tlearn: 0.1575483\ttotal: 297ms\tremaining: 549ms\n",
      "400:\tlearn: 0.1570969\ttotal: 338ms\tremaining: 505ms\n",
      "450:\tlearn: 0.1566731\ttotal: 379ms\tremaining: 461ms\n",
      "500:\tlearn: 0.1562917\ttotal: 421ms\tremaining: 419ms\n",
      "550:\tlearn: 0.1559132\ttotal: 462ms\tremaining: 377ms\n",
      "600:\tlearn: 0.1555002\ttotal: 505ms\tremaining: 335ms\n",
      "650:\tlearn: 0.1551645\ttotal: 545ms\tremaining: 292ms\n",
      "700:\tlearn: 0.1548798\ttotal: 586ms\tremaining: 250ms\n",
      "750:\tlearn: 0.1545780\ttotal: 628ms\tremaining: 208ms\n",
      "800:\tlearn: 0.1543189\ttotal: 670ms\tremaining: 166ms\n",
      "850:\tlearn: 0.1540392\ttotal: 712ms\tremaining: 125ms\n",
      "900:\tlearn: 0.1537545\ttotal: 754ms\tremaining: 82.8ms\n",
      "950:\tlearn: 0.1534810\ttotal: 795ms\tremaining: 41ms\n",
      "999:\tlearn: 0.1532493\ttotal: 836ms\tremaining: 0us\n",
      "0.12077720039304268\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models.fit(train.values, y)\n",
    "stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
    "print(rmsle(y, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과\n",
    "\n",
    "### 모델 별 RMSE\n",
    "- GradientBoostingRegressor : 0.11239171398239439\n",
    "- XGBRegressor : 0.12969515056025335\n",
    "- LGBRegressor : 0.16847294062632265\n",
    "- RandomForestRegressor : 0.10740814007967998\n",
    "- CatBoostRegressor : 0.1410019663622063\n",
    "\n",
    "### Averaged base models class RMSE\n",
    "- Averaged base models score: 0.1633\n",
    "\n",
    "\n",
    "### StackingAveragedModels RMSE\n",
    "- Stacking averaged models score: 0.12077720039304268\n",
    "- averaging한 결과보다 stacking한 결과가 확실히 더 좋게 나오는 것을 확인할 수 있었음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 525345.33519172,  455248.07772935, 1356500.40882783, ...,\n",
       "        462864.91054622,  303551.38860684,  418967.60321552])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.expm1(model_cb.predict(test))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   price\n",
       "0  15035  100000\n",
       "1  15036  100000\n",
       "2  15037  100000\n",
       "3  15038  100000\n",
       "4  15039  100000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "submission_path = join(data_dir, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>5.253453e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>4.552481e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>1.356500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>3.064931e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>3.192258e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  15035  5.253453e+05\n",
       "1  15036  4.552481e+05\n",
       "2  15037  1.356500e+06\n",
       "3  15038  3.064931e+05\n",
       "4  15039  3.192258e+05"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['price'] = prediction\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/kaggle_kakr_housing/data/submission_lgbm_RMSLE_0.164399.csv\n"
     ]
    }
   ],
   "source": [
    "submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, 'lgbm', '0.164399')\n",
    "submission.to_csv(submission_csv_path, index=False)\n",
    "print(submission_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기타 알게된 지식\n",
    "\n",
    "### 1. 앙상블(Ensemble)\n",
    ": 머신러닝에서 주로 쓰이는 알고리즘으로써, 앙상블은 크게 votting,bagging, boosting, stacking이라는 방법이 있음\n",
    "\n",
    "* stacking ensemble : 캐글 점수를 높이고자 할때 주로 쓰임.\n",
    "\n",
    "기존 머신러닝 알고리즘은,\n",
    "- X_train, y_train을 사용하여 model training\n",
    "- validation이 있다면 중간중간 평가를 하며\n",
    "- x_test를 이용해 최종예측하여 prediction값을 가지게 되고,\n",
    "- y_test 와 predict값을 이용해 최종 평가하게 됨\n",
    "\n",
    "하지만, stacking ensemble은 개별 모델이 예측한 데이터를 다시 training set으로 사용해서 학습한다는 것에 큰 차이가 있음.\n",
    "- 원본 데이터의 train, test가 존재\n",
    "- 원본 training data를 3개의 머신러닝 모델(SVM, Rndom forest, LGBM, 등)이 학습\n",
    "- 각 모델마다 X_test를 넣어서 예측 후 predict를 뽑아냄(3개의 predict된 값)\n",
    "- 3개의 predict를 다시 학습 데이터(new training data)로 사용\n",
    "- 최종 model을 하나 선정해 학습(fit)하고 predict하여 최종평가함(개별 모델들의 predict를 다 따로 저장하고 통합해야됨!=데이터를 쌓아주는(stacking) 합치는 ensemble이라는 뜻.)\n",
    "- stacking ensemble은 과적합의 문제점이 있어 잘 사용하지않고 캐글에서만 주로 사용되며, 이때 훈련횟수에 주의해야됨\n",
    "\n",
    "예시)\n",
    "svm_pred = svm.predict(X_test)\n",
    "rf_pred : rf.predict(X_test)\n",
    "lr_pred : lr.predict(X_test)\n",
    "\n",
    "new_data = np.array([svm_pred,rf_pred,lr_pred])\n",
    "new_Data.shape\n",
    "-> 결과값 (3, 114) : 행이 3개(모델이 3개)열이 114개로 되어 있음을 나타냄.\n",
    "\n",
    "new_data = np.transpose(new_data)\n",
    "new_data.shape\n",
    "-> 결과값 (114,3)\n",
    "\n",
    "-> *stacking할 때 데이터의 shape에 주의해야됨(row는 x_test와 일치 해야됨, 밑에 나와있듯이 (ex)열 114개와 일치해야됨)\n",
    "\n",
    "### 2. LightGBM \n",
    ": 트리 기반의 학습 알고리즘인 gradient boosting방식의 프레임 워크\n",
    "- GPU를 활용하며, 메모리를 적게 차지하고 속도가 빠르고 결과가 정확함.\n",
    "- 다른 알고리즘은 학습 나무를 수평으로 확장하는 반면, LGBM은 수직으로 확장함.(leaf-wise tree growth) - 최대 delta loss가 증가하도록 잎의 개수를 정함.(다른 level-wise알고리즘보다 낮은 loss를 달성하는 경향이 있으며, 데이터의 크기가 작은 경우 leaf-wise는 과적합 되기 쉬우므로 max_depth를 줄여줘야함) \n",
    "\n",
    "#### 주요 하이퍼파라미터\n",
    "\n",
    "(1) Object : regression, binary, multiclass\n",
    "\n",
    "(2) metric : mae, rmse, mape, binary_logloss, auc, cross_entropy, kullbac_leibler\n",
    "\n",
    "(3) learning_rate \n",
    "\n",
    "(4) num_interations : 기본값이 100인데 1000정도는 해주는게 좋다함. 너무 크게하면 과적합 발생함, 같은 뜻으로 사용되는 옵션으로서, num_iteration, n_iter, num_tree, num_trees, num_round, num_rounds, num_boos_round, n_estimators\n",
    "\n",
    "(5) max_depth: -1로 설정하면 제한없이 분기함. feature가 많다면 크게 설정해야됨. 파라미터 설정시 우선적으로 설정해야됨.\n",
    "\n",
    "(6) boosting :\n",
    "- 부스팅방법:기본값은 gbdt이며 정확도가 중요할때는 딥러닝의 드랍아웃과 같은 dart를 사용함. 샘플링을 이용하는 goss도 있음.\n",
    "ex) default  = gbdt, options: gdbt, rf, dart, goss\n",
    "\n",
    "(7) bagging_fraction  배깅을 하기 위해서 데이터를 랜덤 샘플링하여 학습에 사용해야함. 비율은 0<fraction<=1이며 0이 되지않게 해야함. \n",
    "\n",
    "(8) feature_fraction : feature_fraction이 1보다 작다면 lgm은 매 iteration(tree)마다 다른 feature를 랜덤하게 추출하여 학습하게 됨. 만약, 0.8로 값을 설정하면 매 tree를 구성할 때, feature의 80%만 랜덤하게 선택함. 과적합을 방지하기 위해 사용할 수있으며 학습속도가 향상됨.\n",
    "\n",
    "(9) scale_pos_weight : 클래스 불균형의 데이터 셋에서 weight를 주는 방식으로positive를 증가시킴. 기본값은 1이며 불균형의 정도에 따라 조절함.\n",
    "\n",
    "(10) early_stopping_round : validation 셋에ㅐ서 평가지표가 더이상 향상되지 않으면 학습을 정지함. 평가지표의 향상이 n round이 상 지속되면 학습을 저이함\n",
    "\n",
    "(11) lambda_l1, lambda_l2 : 정규화를 통해 과적합을 방지 할 수있지만, 정확도를 저하시킬 수도 있기 때문에 일반적으로 default값인 0으로 둠.\n",
    "\n",
    "결론\n",
    "\n",
    "(1) 더 빠른 속도\n",
    "- bagging_fraction\n",
    "- max_bin은 작게\n",
    "- save_binary를 쓰면 데이터 로딩속도가 빨라짐\n",
    "- parallel learning사용\n",
    "\n",
    "(2) 더 높은 정확도\n",
    "- max_bin을 크게\n",
    "- num_iterations 는 크게하고 learning_rate는 작게\n",
    "- num_leaves를 크게(과적합 원인될 수 있으므로 주의)\n",
    "- boosting 알고리즘 'dart'사용\n",
    "\n",
    "(3) 과적합을 줄이기\n",
    "- max_bin을 작게\n",
    "- num_leaves를 작게\n",
    "- min_data_in_leaf와 min_sum_hessian_in_leaf사용하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고 : \n",
    "\n",
    "\n",
    "피어슨상관관계 지수 : https://lunch-box.tistory.com/94\n",
    "\n",
    "LGBM 모델 : https://greatjoy.tistory.com/72 \n",
    "\n",
    "stacking_ensemble ; https://lsjsj92.tistory.com/558\n",
    "\n",
    "과제참고 : https://github.com/JaeHeee/AIFFEL_Project/blob/master/EXPLORATION/EXPLORATION%208.%20%EB%82%98%EC%9D%98%20%EC%B2%AB%20%EB%B2%88%EC%A7%B8%20%EC%BA%90%EA%B8%80%20%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C%2C%20%EB%AC%B4%EC%9E%91%EC%A0%95%20%EB%94%B0%EB%9D%BC%ED%95%B4%EB%B3%B4%EA%B8%B0.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
